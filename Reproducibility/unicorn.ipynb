{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flash Evaluation on Unicorn Dataset:\n",
    "\n",
    "This notebook is dedicated to evaluating Flash on the Unicorn datasets, which are graph-level in nature. We employ Flash in graph-level detection mode to analyze this dataset effectively. Upon completion of the notebook execution, the results will be presented.\n",
    "\n",
    "## Dataset Access: \n",
    "- The Unicorn dataset can be accessed at the following link: [Unicorn Dataset](https://github.com/margoseltzer/shellshock-apt).\n",
    "\n",
    "## Data Parsing and Execution:\n",
    "- The script automatically downloads the parsed dataset.\n",
    "- To obtain the evaluation results, execute all cells within this notebook.\n",
    "\n",
    "## Model Training and Execution Flexibility:\n",
    "- By default, the notebook operates using pre-trained model weights.\n",
    "- Additionally, this notebook offers the flexibility to set parameters for training Graph Neural Networks (GNNs) and word2vec models from scratch.\n",
    "- You can then utilize these freshly trained models to conduct the evaluation. \n",
    "\n",
    "Follow these guidelines for a thorough and efficient analysis of the Unicorn datasets using Flash.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "F1op-CbyLuN4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "warnings.filterwarnings('ignore')\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "import multiprocessing\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1dmezgT9zQ-8ydHrXvJmxwJN-LjPtumbU\n",
      "From (redirected): https://drive.google.com/uc?id=1dmezgT9zQ-8ydHrXvJmxwJN-LjPtumbU&confirm=t&uuid=59a182f2-679b-4eb2-ae70-835020c9108a\n",
      "To: /home/tpiuser2/prov_project/amaan_flash/Flash-IDS-main/unicorn.zip\n",
      "100%|██████████| 97.6M/97.6M [00:06<00:00, 15.9MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'unicorn.zip'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "url = \"https://drive.google.com/file/d/1dmezgT9zQ-8ydHrXvJmxwJN-LjPtumbU/view\"\n",
    "gdown.download(url, quiet=False, use_cookies=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "def unzip_file(zip_path, extract_to):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "zip_path = 'unicorn.zip'\n",
    "extract_to = 'unicorn'\n",
    "unzip_file(zip_path, extract_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Train_Gnn = True\n",
    "Train_Word2vec = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "nM7KaeCbA_mQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import gzip\n",
    "from sklearn.manifold import TSNE\n",
    "import json\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import csv\n",
    "def show(str):\n",
    "\tprint (str + ' ' + time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(time.time())))\n",
    "\n",
    "def parse_data():\n",
    "    for i in range(3):\n",
    "        os.system('tar -zxvf camflow-attack-' + str(i) + '.gz.tar')\n",
    "    for i in range(13):\n",
    "        os.system('tar -zxvf camflow-benign-' + str(i) + '.gz.tar')\n",
    "\n",
    "    os.system('rm error.log')\n",
    "    os.system('rm parse-error-camflow-*')\n",
    "    show('Start processing.')\n",
    "    for i in range(25):\n",
    "        show('Attack graph ' + str(i+125))\n",
    "        f = open('camflow-attack.txt.'+str(i), 'r')\n",
    "        fw = open('unicorn/'+str(i+125)+'.txt', 'w')\n",
    "        for line in f:\n",
    "                tempp = line.strip('\\n').split('\\t')\n",
    "                temp = []\n",
    "                temp.append(tempp[0])\n",
    "                temp.append(tempp[2].split(':')[0])\n",
    "                temp.append(tempp[1])\n",
    "                temp.append(tempp[2].split(':')[1])\n",
    "                temp.append(tempp[2].split(':')[2])\n",
    "                temp.append(tempp[2].split(':')[3])\n",
    "                fw.write(temp[0]+'\\t'+temp[1]+'\\t'+temp[2]+'\\t'+temp[3]+'\\t'+temp[4]+'\\t'+temp[5]+'\\n')\n",
    "        f.close()\n",
    "        fw.close()\n",
    "        os.system('rm camflow-attack.txt.' + str(i))\n",
    "\n",
    "    for i in range(125):\n",
    "        show('Benign graph ' + str(i))\n",
    "        f = open('camflow-normal.txt.'+str(i), 'r')\n",
    "        fw = open('unicorn/'+str(i)+'.txt', 'w')\n",
    "        for line in f:\n",
    "                tempp = line.strip('\\n').split('\\t')\n",
    "                temp = []\n",
    "                temp.append(tempp[0])\n",
    "                temp.append(tempp[2].split(':')[0])\n",
    "                temp.append(tempp[1])\n",
    "                temp.append(tempp[2].split(':')[1])\n",
    "                temp.append(tempp[2].split(':')[2])\n",
    "                temp.append(tempp[2].split(':')[3])\n",
    "                fw.write(temp[0]+'\\t'+temp[1]+'\\t'+temp[2]+'\\t'+temp[3]+'\\t'+temp[4]+'\\t'+temp[5]+'\\n')\n",
    "        f.close()\n",
    "        fw.close()\n",
    "        os.system('rm camflow-normal.txt.' + str(i))\n",
    "    show('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_graph(df):\n",
    "    def process_node(node, action, node_dict, label_dict, dummies, node_type):\n",
    "        node_dict.setdefault(node, []).append(action)\n",
    "        label_dict[node] = dummies.get(getattr(row, node_type), -1)  \n",
    "\n",
    "    nodes = {}\n",
    "    labels = {}\n",
    "    edges = []\n",
    "    dummies = {\n",
    "        \"7998762093665332071\": 0, \"14709879154498484854\": 1, \"10991425273196493354\": 2,\n",
    "        \"14871526952859113360\": 3, \"8771628573506871447\": 4, \"7877121489144997480\": 5,\n",
    "        \"17841021884467483934\": 6, \"7895447931126725167\": 7, \"15125250455093594050\": 8,\n",
    "        \"8664433583651064836\": 9, \"14377490526132269506\": 10, \"15554536683409451879\": 11,\n",
    "        \"8204541918505434145\": 12, \"14356114695140920775\": 13\n",
    "    }\n",
    "\n",
    "    for row in df.itertuples():\n",
    "        process_node(row.actorID, row.action, nodes, labels, dummies, 'actor_type')\n",
    "        process_node(row.objectID, row.action, nodes, labels, dummies, 'object')\n",
    "\n",
    "        edges.append((row.actorID, row.objectID))\n",
    "\n",
    "    features = [nodes[node] for node in nodes]\n",
    "    feat_labels = [labels[node] for node in nodes]\n",
    "    \n",
    "    \n",
    "    edge_index = [[], []]\n",
    "    # for src, dst in edges:\n",
    "    #     src_index = list(nodes.keys()).index(src)\n",
    "    #     dst_index = list(nodes.keys()).index(dst)\n",
    "    #     edge_index[0].append(src_index)\n",
    "    #     edge_index[1].append(dst_index)\n",
    "    \n",
    "    node_index_map = {node: i for i, node in enumerate(nodes.keys())}\n",
    "    for src, dst in tqdm(edges):\n",
    "        src_index = node_index_map[src]\n",
    "        dst_index = node_index_map[dst]\n",
    "        edge_index[0].append(src_index)\n",
    "        edge_index[1].append(dst_index)\n",
    "\n",
    "    return features, feat_labels, edge_index, list(nodes.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "fmXWs1dKIzD8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import SAGEConv, GATConv\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self,in_channel,out_channel):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channel, 32, normalize=True)\n",
    "        self.conv2 = SAGEConv(32, 20, normalize=True)\n",
    "        self.linear = nn.Linear(in_features=20,out_features=out_channel)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.linear(x)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "3PCP6SXwZaif",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from multiprocessing import Pool\n",
    "from itertools import compress\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "class EpochSaver(CallbackAny2Vec):\n",
    "    '''Callback to save model after each epoch.'''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        model.save('trained_weights/unicorn/unicorn.model')\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "P8oBL8LFaeOf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EpochLogger(CallbackAny2Vec):\n",
    "    '''Callback to log information about training'''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_begin(self, model):\n",
    "        print(\"Epoch #{} start\".format(self.epoch))\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        print(\"Epoch #{} end\".format(self.epoch))\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "Se7Ei4tAapVj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = EpochLogger()\n",
    "saver = EpochSaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1507701/1507701 [00:01<00:00, 1188298.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0 start\n",
      "Epoch #0 end\n",
      "Epoch #1 start\n",
      "Epoch #1 end\n",
      "Epoch #2 start\n",
      "Epoch #2 end\n",
      "Epoch #3 start\n",
      "Epoch #3 end\n",
      "Epoch #4 start\n",
      "Epoch #4 end\n",
      "Epoch #5 start\n",
      "Epoch #5 end\n",
      "Epoch #6 start\n",
      "Epoch #6 end\n",
      "Epoch #7 start\n",
      "Epoch #7 end\n",
      "Epoch #8 start\n",
      "Epoch #8 end\n",
      "Epoch #9 start\n",
      "Epoch #9 end\n",
      "Epoch #10 start\n",
      "Epoch #10 end\n",
      "Epoch #11 start\n",
      "Epoch #11 end\n",
      "Epoch #12 start\n",
      "Epoch #12 end\n",
      "Epoch #13 start\n",
      "Epoch #13 end\n",
      "Epoch #14 start\n",
      "Epoch #14 end\n",
      "Epoch #15 start\n",
      "Epoch #15 end\n",
      "Epoch #16 start\n",
      "Epoch #16 end\n",
      "Epoch #17 start\n",
      "Epoch #17 end\n",
      "Epoch #18 start\n",
      "Epoch #18 end\n",
      "Epoch #19 start\n",
      "Epoch #19 end\n",
      "Epoch #20 start\n",
      "Epoch #20 end\n",
      "Epoch #21 start\n",
      "Epoch #21 end\n",
      "Epoch #22 start\n",
      "Epoch #22 end\n",
      "Epoch #23 start\n",
      "Epoch #23 end\n",
      "Epoch #24 start\n",
      "Epoch #24 end\n",
      "Epoch #25 start\n",
      "Epoch #25 end\n",
      "Epoch #26 start\n",
      "Epoch #26 end\n",
      "Epoch #27 start\n",
      "Epoch #27 end\n",
      "Epoch #28 start\n",
      "Epoch #28 end\n",
      "Epoch #29 start\n",
      "Epoch #29 end\n",
      "Epoch #30 start\n",
      "Epoch #30 end\n",
      "Epoch #31 start\n",
      "Epoch #31 end\n",
      "Epoch #32 start\n",
      "Epoch #32 end\n",
      "Epoch #33 start\n",
      "Epoch #33 end\n",
      "Epoch #34 start\n",
      "Epoch #34 end\n",
      "Epoch #35 start\n",
      "Epoch #35 end\n",
      "Epoch #36 start\n",
      "Epoch #36 end\n",
      "Epoch #37 start\n",
      "Epoch #37 end\n",
      "Epoch #38 start\n",
      "Epoch #38 end\n",
      "Epoch #39 start\n",
      "Epoch #39 end\n",
      "Epoch #40 start\n",
      "Epoch #40 end\n",
      "Epoch #41 start\n",
      "Epoch #41 end\n",
      "Epoch #42 start\n",
      "Epoch #42 end\n",
      "Epoch #43 start\n",
      "Epoch #43 end\n",
      "Epoch #44 start\n",
      "Epoch #44 end\n",
      "Epoch #45 start\n",
      "Epoch #45 end\n",
      "Epoch #46 start\n",
      "Epoch #46 end\n",
      "Epoch #47 start\n",
      "Epoch #47 end\n",
      "Epoch #48 start\n",
      "Epoch #48 end\n",
      "Epoch #49 start\n",
      "Epoch #49 end\n",
      "Epoch #50 start\n",
      "Epoch #50 end\n",
      "Epoch #51 start\n",
      "Epoch #51 end\n",
      "Epoch #52 start\n",
      "Epoch #52 end\n",
      "Epoch #53 start\n",
      "Epoch #53 end\n",
      "Epoch #54 start\n",
      "Epoch #54 end\n",
      "Epoch #55 start\n",
      "Epoch #55 end\n",
      "Epoch #56 start\n",
      "Epoch #56 end\n",
      "Epoch #57 start\n",
      "Epoch #57 end\n",
      "Epoch #58 start\n",
      "Epoch #58 end\n",
      "Epoch #59 start\n",
      "Epoch #59 end\n",
      "Epoch #60 start\n",
      "Epoch #60 end\n",
      "Epoch #61 start\n",
      "Epoch #61 end\n",
      "Epoch #62 start\n",
      "Epoch #62 end\n",
      "Epoch #63 start\n",
      "Epoch #63 end\n",
      "Epoch #64 start\n",
      "Epoch #64 end\n",
      "Epoch #65 start\n",
      "Epoch #65 end\n",
      "Epoch #66 start\n",
      "Epoch #66 end\n",
      "Epoch #67 start\n",
      "Epoch #67 end\n",
      "Epoch #68 start\n",
      "Epoch #68 end\n",
      "Epoch #69 start\n",
      "Epoch #69 end\n",
      "Epoch #70 start\n",
      "Epoch #70 end\n",
      "Epoch #71 start\n",
      "Epoch #71 end\n",
      "Epoch #72 start\n",
      "Epoch #72 end\n",
      "Epoch #73 start\n",
      "Epoch #73 end\n",
      "Epoch #74 start\n",
      "Epoch #74 end\n",
      "Epoch #75 start\n",
      "Epoch #75 end\n",
      "Epoch #76 start\n",
      "Epoch #76 end\n",
      "Epoch #77 start\n",
      "Epoch #77 end\n",
      "Epoch #78 start\n",
      "Epoch #78 end\n",
      "Epoch #79 start\n",
      "Epoch #79 end\n",
      "Epoch #80 start\n",
      "Epoch #80 end\n",
      "Epoch #81 start\n",
      "Epoch #81 end\n",
      "Epoch #82 start\n",
      "Epoch #82 end\n",
      "Epoch #83 start\n",
      "Epoch #83 end\n",
      "Epoch #84 start\n",
      "Epoch #84 end\n",
      "Epoch #85 start\n",
      "Epoch #85 end\n",
      "Epoch #86 start\n",
      "Epoch #86 end\n",
      "Epoch #87 start\n",
      "Epoch #87 end\n",
      "Epoch #88 start\n",
      "Epoch #88 end\n",
      "Epoch #89 start\n",
      "Epoch #89 end\n",
      "Epoch #90 start\n",
      "Epoch #90 end\n",
      "Epoch #91 start\n",
      "Epoch #91 end\n",
      "Epoch #92 start\n",
      "Epoch #92 end\n",
      "Epoch #93 start\n",
      "Epoch #93 end\n",
      "Epoch #94 start\n",
      "Epoch #94 end\n",
      "Epoch #95 start\n",
      "Epoch #95 end\n",
      "Epoch #96 start\n",
      "Epoch #96 end\n",
      "Epoch #97 start\n",
      "Epoch #97 end\n",
      "Epoch #98 start\n",
      "Epoch #98 end\n",
      "Epoch #99 start\n",
      "Epoch #99 end\n",
      "Epoch #100 start\n",
      "Epoch #100 end\n",
      "Epoch #101 start\n",
      "Epoch #101 end\n",
      "Epoch #102 start\n",
      "Epoch #102 end\n",
      "Epoch #103 start\n",
      "Epoch #103 end\n",
      "Epoch #104 start\n",
      "Epoch #104 end\n",
      "Epoch #105 start\n",
      "Epoch #105 end\n",
      "Epoch #106 start\n",
      "Epoch #106 end\n",
      "Epoch #107 start\n",
      "Epoch #107 end\n",
      "Epoch #108 start\n",
      "Epoch #108 end\n",
      "Epoch #109 start\n",
      "Epoch #109 end\n",
      "Epoch #110 start\n",
      "Epoch #110 end\n",
      "Epoch #111 start\n",
      "Epoch #111 end\n",
      "Epoch #112 start\n",
      "Epoch #112 end\n",
      "Epoch #113 start\n",
      "Epoch #113 end\n",
      "Epoch #114 start\n",
      "Epoch #114 end\n",
      "Epoch #115 start\n",
      "Epoch #115 end\n",
      "Epoch #116 start\n",
      "Epoch #116 end\n",
      "Epoch #117 start\n",
      "Epoch #117 end\n",
      "Epoch #118 start\n",
      "Epoch #118 end\n",
      "Epoch #119 start\n",
      "Epoch #119 end\n",
      "Epoch #120 start\n",
      "Epoch #120 end\n",
      "Epoch #121 start\n",
      "Epoch #121 end\n",
      "Epoch #122 start\n",
      "Epoch #122 end\n",
      "Epoch #123 start\n",
      "Epoch #123 end\n",
      "Epoch #124 start\n",
      "Epoch #124 end\n",
      "Epoch #125 start\n",
      "Epoch #125 end\n",
      "Epoch #126 start\n",
      "Epoch #126 end\n",
      "Epoch #127 start\n",
      "Epoch #127 end\n",
      "Epoch #128 start\n",
      "Epoch #128 end\n",
      "Epoch #129 start\n",
      "Epoch #129 end\n",
      "Epoch #130 start\n",
      "Epoch #130 end\n",
      "Epoch #131 start\n",
      "Epoch #131 end\n",
      "Epoch #132 start\n",
      "Epoch #132 end\n",
      "Epoch #133 start\n",
      "Epoch #133 end\n",
      "Epoch #134 start\n",
      "Epoch #134 end\n",
      "Epoch #135 start\n",
      "Epoch #135 end\n",
      "Epoch #136 start\n",
      "Epoch #136 end\n",
      "Epoch #137 start\n",
      "Epoch #137 end\n",
      "Epoch #138 start\n",
      "Epoch #138 end\n",
      "Epoch #139 start\n",
      "Epoch #139 end\n",
      "Epoch #140 start\n",
      "Epoch #140 end\n",
      "Epoch #141 start\n",
      "Epoch #141 end\n",
      "Epoch #142 start\n",
      "Epoch #142 end\n",
      "Epoch #143 start\n",
      "Epoch #143 end\n",
      "Epoch #144 start\n",
      "Epoch #144 end\n",
      "Epoch #145 start\n",
      "Epoch #145 end\n",
      "Epoch #146 start\n",
      "Epoch #146 end\n",
      "Epoch #147 start\n",
      "Epoch #147 end\n",
      "Epoch #148 start\n",
      "Epoch #148 end\n",
      "Epoch #149 start\n",
      "Epoch #149 end\n",
      "Epoch #150 start\n",
      "Epoch #150 end\n",
      "Epoch #151 start\n",
      "Epoch #151 end\n",
      "Epoch #152 start\n",
      "Epoch #152 end\n",
      "Epoch #153 start\n",
      "Epoch #153 end\n",
      "Epoch #154 start\n",
      "Epoch #154 end\n",
      "Epoch #155 start\n",
      "Epoch #155 end\n",
      "Epoch #156 start\n",
      "Epoch #156 end\n",
      "Epoch #157 start\n",
      "Epoch #157 end\n",
      "Epoch #158 start\n",
      "Epoch #158 end\n",
      "Epoch #159 start\n",
      "Epoch #159 end\n",
      "Epoch #160 start\n",
      "Epoch #160 end\n",
      "Epoch #161 start\n",
      "Epoch #161 end\n",
      "Epoch #162 start\n",
      "Epoch #162 end\n",
      "Epoch #163 start\n",
      "Epoch #163 end\n",
      "Epoch #164 start\n",
      "Epoch #164 end\n",
      "Epoch #165 start\n",
      "Epoch #165 end\n",
      "Epoch #166 start\n",
      "Epoch #166 end\n",
      "Epoch #167 start\n",
      "Epoch #167 end\n",
      "Epoch #168 start\n",
      "Epoch #168 end\n",
      "Epoch #169 start\n",
      "Epoch #169 end\n",
      "Epoch #170 start\n",
      "Epoch #170 end\n",
      "Epoch #171 start\n",
      "Epoch #171 end\n",
      "Epoch #172 start\n",
      "Epoch #172 end\n",
      "Epoch #173 start\n",
      "Epoch #173 end\n",
      "Epoch #174 start\n",
      "Epoch #174 end\n",
      "Epoch #175 start\n",
      "Epoch #175 end\n",
      "Epoch #176 start\n",
      "Epoch #176 end\n",
      "Epoch #177 start\n",
      "Epoch #177 end\n",
      "Epoch #178 start\n",
      "Epoch #178 end\n",
      "Epoch #179 start\n",
      "Epoch #179 end\n",
      "Epoch #180 start\n",
      "Epoch #180 end\n",
      "Epoch #181 start\n",
      "Epoch #181 end\n",
      "Epoch #182 start\n",
      "Epoch #182 end\n",
      "Epoch #183 start\n",
      "Epoch #183 end\n",
      "Epoch #184 start\n",
      "Epoch #184 end\n",
      "Epoch #185 start\n",
      "Epoch #185 end\n",
      "Epoch #186 start\n",
      "Epoch #186 end\n",
      "Epoch #187 start\n",
      "Epoch #187 end\n",
      "Epoch #188 start\n",
      "Epoch #188 end\n",
      "Epoch #189 start\n",
      "Epoch #189 end\n",
      "Epoch #190 start\n",
      "Epoch #190 end\n",
      "Epoch #191 start\n",
      "Epoch #191 end\n",
      "Epoch #192 start\n",
      "Epoch #192 end\n",
      "Epoch #193 start\n",
      "Epoch #193 end\n",
      "Epoch #194 start\n",
      "Epoch #194 end\n",
      "Epoch #195 start\n",
      "Epoch #195 end\n",
      "Epoch #196 start\n",
      "Epoch #196 end\n",
      "Epoch #197 start\n",
      "Epoch #197 end\n",
      "Epoch #198 start\n",
      "Epoch #198 end\n",
      "Epoch #199 start\n",
      "Epoch #199 end\n",
      "Epoch #200 start\n",
      "Epoch #200 end\n",
      "Epoch #201 start\n",
      "Epoch #201 end\n",
      "Epoch #202 start\n",
      "Epoch #202 end\n",
      "Epoch #203 start\n",
      "Epoch #203 end\n",
      "Epoch #204 start\n",
      "Epoch #204 end\n",
      "Epoch #205 start\n",
      "Epoch #205 end\n",
      "Epoch #206 start\n",
      "Epoch #206 end\n",
      "Epoch #207 start\n",
      "Epoch #207 end\n",
      "Epoch #208 start\n",
      "Epoch #208 end\n",
      "Epoch #209 start\n",
      "Epoch #209 end\n",
      "Epoch #210 start\n",
      "Epoch #210 end\n",
      "Epoch #211 start\n",
      "Epoch #211 end\n",
      "Epoch #212 start\n",
      "Epoch #212 end\n",
      "Epoch #213 start\n",
      "Epoch #213 end\n",
      "Epoch #214 start\n",
      "Epoch #214 end\n",
      "Epoch #215 start\n",
      "Epoch #215 end\n",
      "Epoch #216 start\n",
      "Epoch #216 end\n",
      "Epoch #217 start\n",
      "Epoch #217 end\n",
      "Epoch #218 start\n",
      "Epoch #218 end\n",
      "Epoch #219 start\n",
      "Epoch #219 end\n",
      "Epoch #220 start\n",
      "Epoch #220 end\n",
      "Epoch #221 start\n",
      "Epoch #221 end\n",
      "Epoch #222 start\n",
      "Epoch #222 end\n",
      "Epoch #223 start\n",
      "Epoch #223 end\n",
      "Epoch #224 start\n",
      "Epoch #224 end\n",
      "Epoch #225 start\n",
      "Epoch #225 end\n",
      "Epoch #226 start\n",
      "Epoch #226 end\n",
      "Epoch #227 start\n",
      "Epoch #227 end\n",
      "Epoch #228 start\n",
      "Epoch #228 end\n",
      "Epoch #229 start\n",
      "Epoch #229 end\n",
      "Epoch #230 start\n",
      "Epoch #230 end\n",
      "Epoch #231 start\n",
      "Epoch #231 end\n",
      "Epoch #232 start\n",
      "Epoch #232 end\n",
      "Epoch #233 start\n",
      "Epoch #233 end\n",
      "Epoch #234 start\n",
      "Epoch #234 end\n",
      "Epoch #235 start\n",
      "Epoch #235 end\n",
      "Epoch #236 start\n",
      "Epoch #236 end\n",
      "Epoch #237 start\n",
      "Epoch #237 end\n",
      "Epoch #238 start\n",
      "Epoch #238 end\n",
      "Epoch #239 start\n",
      "Epoch #239 end\n",
      "Epoch #240 start\n",
      "Epoch #240 end\n",
      "Epoch #241 start\n",
      "Epoch #241 end\n",
      "Epoch #242 start\n",
      "Epoch #242 end\n",
      "Epoch #243 start\n",
      "Epoch #243 end\n",
      "Epoch #244 start\n",
      "Epoch #244 end\n",
      "Epoch #245 start\n",
      "Epoch #245 end\n",
      "Epoch #246 start\n",
      "Epoch #246 end\n",
      "Epoch #247 start\n",
      "Epoch #247 end\n",
      "Epoch #248 start\n",
      "Epoch #248 end\n",
      "Epoch #249 start\n",
      "Epoch #249 end\n",
      "Epoch #250 start\n",
      "Epoch #250 end\n",
      "Epoch #251 start\n",
      "Epoch #251 end\n",
      "Epoch #252 start\n",
      "Epoch #252 end\n",
      "Epoch #253 start\n",
      "Epoch #253 end\n",
      "Epoch #254 start\n",
      "Epoch #254 end\n",
      "Epoch #255 start\n",
      "Epoch #255 end\n",
      "Epoch #256 start\n",
      "Epoch #256 end\n",
      "Epoch #257 start\n",
      "Epoch #257 end\n",
      "Epoch #258 start\n",
      "Epoch #258 end\n",
      "Epoch #259 start\n",
      "Epoch #259 end\n",
      "Epoch #260 start\n",
      "Epoch #260 end\n",
      "Epoch #261 start\n",
      "Epoch #261 end\n",
      "Epoch #262 start\n",
      "Epoch #262 end\n",
      "Epoch #263 start\n",
      "Epoch #263 end\n",
      "Epoch #264 start\n",
      "Epoch #264 end\n",
      "Epoch #265 start\n",
      "Epoch #265 end\n",
      "Epoch #266 start\n",
      "Epoch #266 end\n",
      "Epoch #267 start\n",
      "Epoch #267 end\n",
      "Epoch #268 start\n",
      "Epoch #268 end\n",
      "Epoch #269 start\n",
      "Epoch #269 end\n",
      "Epoch #270 start\n",
      "Epoch #270 end\n",
      "Epoch #271 start\n",
      "Epoch #271 end\n",
      "Epoch #272 start\n",
      "Epoch #272 end\n",
      "Epoch #273 start\n",
      "Epoch #273 end\n",
      "Epoch #274 start\n",
      "Epoch #274 end\n",
      "Epoch #275 start\n",
      "Epoch #275 end\n",
      "Epoch #276 start\n",
      "Epoch #276 end\n",
      "Epoch #277 start\n",
      "Epoch #277 end\n",
      "Epoch #278 start\n",
      "Epoch #278 end\n",
      "Epoch #279 start\n",
      "Epoch #279 end\n",
      "Epoch #280 start\n",
      "Epoch #280 end\n",
      "Epoch #281 start\n",
      "Epoch #281 end\n",
      "Epoch #282 start\n",
      "Epoch #282 end\n",
      "Epoch #283 start\n",
      "Epoch #283 end\n",
      "Epoch #284 start\n",
      "Epoch #284 end\n",
      "Epoch #285 start\n",
      "Epoch #285 end\n",
      "Epoch #286 start\n",
      "Epoch #286 end\n",
      "Epoch #287 start\n",
      "Epoch #287 end\n",
      "Epoch #288 start\n",
      "Epoch #288 end\n",
      "Epoch #289 start\n",
      "Epoch #289 end\n",
      "Epoch #290 start\n",
      "Epoch #290 end\n",
      "Epoch #291 start\n",
      "Epoch #291 end\n",
      "Epoch #292 start\n",
      "Epoch #292 end\n",
      "Epoch #293 start\n",
      "Epoch #293 end\n",
      "Epoch #294 start\n",
      "Epoch #294 end\n",
      "Epoch #295 start\n",
      "Epoch #295 end\n",
      "Epoch #296 start\n",
      "Epoch #296 end\n",
      "Epoch #297 start\n",
      "Epoch #297 end\n",
      "Epoch #298 start\n",
      "Epoch #298 end\n",
      "Epoch #299 start\n",
      "Epoch #299 end\n"
     ]
    }
   ],
   "source": [
    "if Train_Word2vec:\n",
    "    comb_data = []\n",
    "    for i in range(20):\n",
    "        print(i)\n",
    "        f = open(f\"unicorn/{i}.txt\")\n",
    "        data = f.read().split('\\n')\n",
    "        data = [line.split('\\t') for line in data]\n",
    "        comb_data = comb_data + data\n",
    "\n",
    "    df = pd.DataFrame (comb_data, columns = ['actorID', 'actor_type','objectID','object','action','timestamp'])\n",
    "    df.sort_values(by='timestamp', ascending=True,inplace=True)\n",
    "    df = df.dropna()\n",
    "    phrases,labels,edges,mapp = prepare_graph(df)\n",
    "    \n",
    "    word2vec = Word2Vec(sentences=phrases, vector_size=30, window=5, min_count=1, workers=8,epochs=300,callbacks=[saver,logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "p3TAi69zI1bO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "model = GCN(30,14).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "Vn_pMyt5Jd-6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "class PositionalEncoder:\n",
    "\n",
    "    def __init__(self, d_model, max_len=100000):\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        self.pe = torch.zeros(max_len, d_model)\n",
    "        self.pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "    def embed(self, x):\n",
    "        return x + self.pe[:x.size(0)]\n",
    "\n",
    "def infer(document):\n",
    "    \n",
    "    if Train_Word2vec:                  ## added.\n",
    "        word_embeddings = [word2vec.wv[word] for word in document if word in  word2vec.wv]\n",
    "    else:\n",
    "        word_embeddings = [w2vmodel.wv[word] for word in document if word in  w2vmodel.wv]\n",
    "        \n",
    "    if not word_embeddings:\n",
    "        return np.zeros(20)\n",
    "\n",
    "    output_embedding = torch.tensor(word_embeddings, dtype=torch.float)\n",
    "    if len(document) < 100000:\n",
    "        output_embedding = encoder.embed(output_embedding)\n",
    "\n",
    "    output_embedding = output_embedding.detach().cpu().numpy()\n",
    "    return np.mean(output_embedding, axis=0)\n",
    "\n",
    "encoder = PositionalEncoder(30)\n",
    "w2vmodel = Word2Vec.load(\"trained_weights/unicorn/unicorn.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 689309,
     "status": "ok",
     "timestamp": 1673566932746,
     "user": {
      "displayName": "Mati Ur Rehman",
      "userId": "04281203290774044297"
     },
     "user_tz": 300
    },
    "id": "Gclj6HVL17lD",
    "outputId": "f60fadea-a7db-471f-defe-fee744f6ef25",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116685/116685 [00:00<00:00, 648357.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 19594 nodes still misclassified \n",
      "\n",
      "Model# 1. 16067 nodes still misclassified \n",
      "\n",
      "Model# 2. 12690 nodes still misclassified \n",
      "\n",
      "Model# 3. 8135 nodes still misclassified \n",
      "\n",
      "Model# 4. 6142 nodes still misclassified \n",
      "\n",
      "Model# 5. 4936 nodes still misclassified \n",
      "\n",
      "Model# 6. 4693 nodes still misclassified \n",
      "\n",
      "Model# 7. 4460 nodes still misclassified \n",
      "\n",
      "Model# 8. 4338 nodes still misclassified \n",
      "\n",
      "Model# 9. 4178 nodes still misclassified \n",
      "\n",
      "Model# 10. 4101 nodes still misclassified \n",
      "\n",
      "Model# 11. 3503 nodes still misclassified \n",
      "\n",
      "Model# 12. 3472 nodes still misclassified \n",
      "\n",
      "Model# 13. 3416 nodes still misclassified \n",
      "\n",
      "Model# 14. 3376 nodes still misclassified \n",
      "\n",
      "Model# 15. 3329 nodes still misclassified \n",
      "\n",
      "Model# 16. 3295 nodes still misclassified \n",
      "\n",
      "Model# 17. 2770 nodes still misclassified \n",
      "\n",
      "Model# 18. 2753 nodes still misclassified \n",
      "\n",
      "Model# 19. 2750 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97195/97195 [00:00<00:00, 1284847.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5945 nodes still misclassified \n",
      "\n",
      "Model# 1. 5245 nodes still misclassified \n",
      "\n",
      "Model# 2. 4104 nodes still misclassified \n",
      "\n",
      "Model# 3. 3847 nodes still misclassified \n",
      "\n",
      "Model# 4. 3284 nodes still misclassified \n",
      "\n",
      "Model# 5. 3047 nodes still misclassified \n",
      "\n",
      "Model# 6. 2982 nodes still misclassified \n",
      "\n",
      "Model# 7. 2916 nodes still misclassified \n",
      "\n",
      "Model# 8. 2190 nodes still misclassified \n",
      "\n",
      "Model# 9. 1939 nodes still misclassified \n",
      "\n",
      "Model# 10. 1908 nodes still misclassified \n",
      "\n",
      "Model# 11. 1619 nodes still misclassified \n",
      "\n",
      "Model# 12. 1610 nodes still misclassified \n",
      "\n",
      "Model# 13. 1599 nodes still misclassified \n",
      "\n",
      "Model# 14. 1596 nodes still misclassified \n",
      "\n",
      "Model# 15. 1591 nodes still misclassified \n",
      "\n",
      "Model# 16. 1585 nodes still misclassified \n",
      "\n",
      "Model# 17. 1578 nodes still misclassified \n",
      "\n",
      "Model# 18. 1570 nodes still misclassified \n",
      "\n",
      "Model# 19. 1557 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87587/87587 [00:00<00:00, 1294907.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1999 nodes still misclassified \n",
      "\n",
      "Model# 1. 1981 nodes still misclassified \n",
      "\n",
      "Model# 2. 1969 nodes still misclassified \n",
      "\n",
      "Model# 3. 1936 nodes still misclassified \n",
      "\n",
      "Model# 4. 1870 nodes still misclassified \n",
      "\n",
      "Model# 5. 1670 nodes still misclassified \n",
      "\n",
      "Model# 6. 1511 nodes still misclassified \n",
      "\n",
      "Model# 7. 1452 nodes still misclassified \n",
      "\n",
      "Model# 8. 1428 nodes still misclassified \n",
      "\n",
      "Model# 9. 1421 nodes still misclassified \n",
      "\n",
      "Model# 10. 1353 nodes still misclassified \n",
      "\n",
      "Model# 11. 1114 nodes still misclassified \n",
      "\n",
      "Model# 12. 876 nodes still misclassified \n",
      "\n",
      "Model# 13. 875 nodes still misclassified \n",
      "\n",
      "Model# 14. 858 nodes still misclassified \n",
      "\n",
      "Model# 15. 816 nodes still misclassified \n",
      "\n",
      "Model# 16. 815 nodes still misclassified \n",
      "\n",
      "Model# 17. 813 nodes still misclassified \n",
      "\n",
      "Model# 18. 812 nodes still misclassified \n",
      "\n",
      "Model# 19. 774 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87589/87589 [00:00<00:00, 732999.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 2207 nodes still misclassified \n",
      "\n",
      "Model# 1. 1755 nodes still misclassified \n",
      "\n",
      "Model# 2. 1623 nodes still misclassified \n",
      "\n",
      "Model# 3. 1248 nodes still misclassified \n",
      "\n",
      "Model# 4. 1244 nodes still misclassified \n",
      "\n",
      "Model# 5. 1243 nodes still misclassified \n",
      "\n",
      "Model# 6. 1243 nodes still misclassified \n",
      "\n",
      "Model# 7. 1229 nodes still misclassified \n",
      "\n",
      "Model# 8. 844 nodes still misclassified \n",
      "\n",
      "Model# 9. 842 nodes still misclassified \n",
      "\n",
      "Model# 10. 840 nodes still misclassified \n",
      "\n",
      "Model# 11. 838 nodes still misclassified \n",
      "\n",
      "Model# 12. 835 nodes still misclassified \n",
      "\n",
      "Model# 13. 834 nodes still misclassified \n",
      "\n",
      "Model# 14. 832 nodes still misclassified \n",
      "\n",
      "Model# 15. 830 nodes still misclassified \n",
      "\n",
      "Model# 16. 830 nodes still misclassified \n",
      "\n",
      "Model# 17. 830 nodes still misclassified \n",
      "\n",
      "Model# 18. 826 nodes still misclassified \n",
      "\n",
      "Model# 19. 823 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77885/77885 [00:00<00:00, 1410817.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 2317 nodes still misclassified \n",
      "\n",
      "Model# 1. 2007 nodes still misclassified \n",
      "\n",
      "Model# 2. 1325 nodes still misclassified \n",
      "\n",
      "Model# 3. 1311 nodes still misclassified \n",
      "\n",
      "Model# 4. 1284 nodes still misclassified \n",
      "\n",
      "Model# 5. 1030 nodes still misclassified \n",
      "\n",
      "Model# 6. 944 nodes still misclassified \n",
      "\n",
      "Model# 7. 699 nodes still misclassified \n",
      "\n",
      "Model# 8. 698 nodes still misclassified \n",
      "\n",
      "Model# 9. 693 nodes still misclassified \n",
      "\n",
      "Model# 10. 689 nodes still misclassified \n",
      "\n",
      "Model# 11. 688 nodes still misclassified \n",
      "\n",
      "Model# 12. 599 nodes still misclassified \n",
      "\n",
      "Model# 13. 595 nodes still misclassified \n",
      "\n",
      "Model# 14. 595 nodes still misclassified \n",
      "\n",
      "Model# 15. 595 nodes still misclassified \n",
      "\n",
      "Model# 16. 595 nodes still misclassified \n",
      "\n",
      "Model# 17. 595 nodes still misclassified \n",
      "\n",
      "Model# 18. 595 nodes still misclassified \n",
      "\n",
      "Model# 19. 595 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77794/77794 [00:00<00:00, 1311435.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1992 nodes still misclassified \n",
      "\n",
      "Model# 1. 1862 nodes still misclassified \n",
      "\n",
      "Model# 2. 1522 nodes still misclassified \n",
      "\n",
      "Model# 3. 999 nodes still misclassified \n",
      "\n",
      "Model# 4. 933 nodes still misclassified \n",
      "\n",
      "Model# 5. 888 nodes still misclassified \n",
      "\n",
      "Model# 6. 857 nodes still misclassified \n",
      "\n",
      "Model# 7. 850 nodes still misclassified \n",
      "\n",
      "Model# 8. 729 nodes still misclassified \n",
      "\n",
      "Model# 9. 722 nodes still misclassified \n",
      "\n",
      "Model# 10. 716 nodes still misclassified \n",
      "\n",
      "Model# 11. 715 nodes still misclassified \n",
      "\n",
      "Model# 12. 711 nodes still misclassified \n",
      "\n",
      "Model# 13. 711 nodes still misclassified \n",
      "\n",
      "Model# 14. 708 nodes still misclassified \n",
      "\n",
      "Model# 15. 702 nodes still misclassified \n",
      "\n",
      "Model# 16. 691 nodes still misclassified \n",
      "\n",
      "Model# 17. 691 nodes still misclassified \n",
      "\n",
      "Model# 18. 691 nodes still misclassified \n",
      "\n",
      "Model# 19. 689 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77826/77826 [00:00<00:00, 1385591.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1812 nodes still misclassified \n",
      "\n",
      "Model# 1. 1691 nodes still misclassified \n",
      "\n",
      "Model# 2. 1666 nodes still misclassified \n",
      "\n",
      "Model# 3. 1635 nodes still misclassified \n",
      "\n",
      "Model# 4. 1616 nodes still misclassified \n",
      "\n",
      "Model# 5. 1555 nodes still misclassified \n",
      "\n",
      "Model# 6. 1547 nodes still misclassified \n",
      "\n",
      "Model# 7. 899 nodes still misclassified \n",
      "\n",
      "Model# 8. 897 nodes still misclassified \n",
      "\n",
      "Model# 9. 896 nodes still misclassified \n",
      "\n",
      "Model# 10. 895 nodes still misclassified \n",
      "\n",
      "Model# 11. 839 nodes still misclassified \n",
      "\n",
      "Model# 12. 837 nodes still misclassified \n",
      "\n",
      "Model# 13. 836 nodes still misclassified \n",
      "\n",
      "Model# 14. 788 nodes still misclassified \n",
      "\n",
      "Model# 15. 787 nodes still misclassified \n",
      "\n",
      "Model# 16. 744 nodes still misclassified \n",
      "\n",
      "Model# 17. 694 nodes still misclassified \n",
      "\n",
      "Model# 18. 693 nodes still misclassified \n",
      "\n",
      "Model# 19. 690 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68071/68071 [00:00<00:00, 1367675.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1655 nodes still misclassified \n",
      "\n",
      "Model# 1. 1603 nodes still misclassified \n",
      "\n",
      "Model# 2. 1430 nodes still misclassified \n",
      "\n",
      "Model# 3. 1198 nodes still misclassified \n",
      "\n",
      "Model# 4. 1133 nodes still misclassified \n",
      "\n",
      "Model# 5. 1074 nodes still misclassified \n",
      "\n",
      "Model# 6. 840 nodes still misclassified \n",
      "\n",
      "Model# 7. 799 nodes still misclassified \n",
      "\n",
      "Model# 8. 773 nodes still misclassified \n",
      "\n",
      "Model# 9. 765 nodes still misclassified \n",
      "\n",
      "Model# 10. 757 nodes still misclassified \n",
      "\n",
      "Model# 11. 684 nodes still misclassified \n",
      "\n",
      "Model# 12. 614 nodes still misclassified \n",
      "\n",
      "Model# 13. 614 nodes still misclassified \n",
      "\n",
      "Model# 14. 614 nodes still misclassified \n",
      "\n",
      "Model# 15. 612 nodes still misclassified \n",
      "\n",
      "Model# 16. 606 nodes still misclassified \n",
      "\n",
      "Model# 17. 602 nodes still misclassified \n",
      "\n",
      "Model# 18. 600 nodes still misclassified \n",
      "\n",
      "Model# 19. 600 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68176/68176 [00:00<00:00, 673391.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1434 nodes still misclassified \n",
      "\n",
      "Model# 1. 1431 nodes still misclassified \n",
      "\n",
      "Model# 2. 1427 nodes still misclassified \n",
      "\n",
      "Model# 3. 1421 nodes still misclassified \n",
      "\n",
      "Model# 4. 1420 nodes still misclassified \n",
      "\n",
      "Model# 5. 1400 nodes still misclassified \n",
      "\n",
      "Model# 6. 1398 nodes still misclassified \n",
      "\n",
      "Model# 7. 1395 nodes still misclassified \n",
      "\n",
      "Model# 8. 1388 nodes still misclassified \n",
      "\n",
      "Model# 9. 748 nodes still misclassified \n",
      "\n",
      "Model# 10. 740 nodes still misclassified \n",
      "\n",
      "Model# 11. 732 nodes still misclassified \n",
      "\n",
      "Model# 12. 716 nodes still misclassified \n",
      "\n",
      "Model# 13. 704 nodes still misclassified \n",
      "\n",
      "Model# 14. 704 nodes still misclassified \n",
      "\n",
      "Model# 15. 645 nodes still misclassified \n",
      "\n",
      "Model# 16. 643 nodes still misclassified \n",
      "\n",
      "Model# 17. 585 nodes still misclassified \n",
      "\n",
      "Model# 18. 584 nodes still misclassified \n",
      "\n",
      "Model# 19. 584 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68024/68024 [00:00<00:00, 1369617.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1994 nodes still misclassified \n",
      "\n",
      "Model# 1. 1914 nodes still misclassified \n",
      "\n",
      "Model# 2. 1860 nodes still misclassified \n",
      "\n",
      "Model# 3. 1713 nodes still misclassified \n",
      "\n",
      "Model# 4. 1427 nodes still misclassified \n",
      "\n",
      "Model# 5. 1404 nodes still misclassified \n",
      "\n",
      "Model# 6. 1371 nodes still misclassified \n",
      "\n",
      "Model# 7. 1202 nodes still misclassified \n",
      "\n",
      "Model# 8. 1191 nodes still misclassified \n",
      "\n",
      "Model# 9. 1176 nodes still misclassified \n",
      "\n",
      "Model# 10. 748 nodes still misclassified \n",
      "\n",
      "Model# 11. 742 nodes still misclassified \n",
      "\n",
      "Model# 12. 732 nodes still misclassified \n",
      "\n",
      "Model# 13. 731 nodes still misclassified \n",
      "\n",
      "Model# 14. 731 nodes still misclassified \n",
      "\n",
      "Model# 15. 731 nodes still misclassified \n",
      "\n",
      "Model# 16. 731 nodes still misclassified \n",
      "\n",
      "Model# 17. 731 nodes still misclassified \n",
      "\n",
      "Model# 18. 729 nodes still misclassified \n",
      "\n",
      "Model# 19. 715 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68143/68143 [00:00<00:00, 1373741.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1525 nodes still misclassified \n",
      "\n",
      "Model# 1. 1447 nodes still misclassified \n",
      "\n",
      "Model# 2. 1291 nodes still misclassified \n",
      "\n",
      "Model# 3. 1255 nodes still misclassified \n",
      "\n",
      "Model# 4. 1223 nodes still misclassified \n",
      "\n",
      "Model# 5. 1221 nodes still misclassified \n",
      "\n",
      "Model# 6. 1218 nodes still misclassified \n",
      "\n",
      "Model# 7. 1210 nodes still misclassified \n",
      "\n",
      "Model# 8. 1208 nodes still misclassified \n",
      "\n",
      "Model# 9. 698 nodes still misclassified \n",
      "\n",
      "Model# 10. 697 nodes still misclassified \n",
      "\n",
      "Model# 11. 692 nodes still misclassified \n",
      "\n",
      "Model# 12. 692 nodes still misclassified \n",
      "\n",
      "Model# 13. 692 nodes still misclassified \n",
      "\n",
      "Model# 14. 691 nodes still misclassified \n",
      "\n",
      "Model# 15. 690 nodes still misclassified \n",
      "\n",
      "Model# 16. 690 nodes still misclassified \n",
      "\n",
      "Model# 17. 690 nodes still misclassified \n",
      "\n",
      "Model# 18. 690 nodes still misclassified \n",
      "\n",
      "Model# 19. 689 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68081/68081 [00:00<00:00, 1309056.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1499 nodes still misclassified \n",
      "\n",
      "Model# 1. 1431 nodes still misclassified \n",
      "\n",
      "Model# 2. 1277 nodes still misclassified \n",
      "\n",
      "Model# 3. 1114 nodes still misclassified \n",
      "\n",
      "Model# 4. 944 nodes still misclassified \n",
      "\n",
      "Model# 5. 897 nodes still misclassified \n",
      "\n",
      "Model# 6. 849 nodes still misclassified \n",
      "\n",
      "Model# 7. 823 nodes still misclassified \n",
      "\n",
      "Model# 8. 819 nodes still misclassified \n",
      "\n",
      "Model# 9. 813 nodes still misclassified \n",
      "\n",
      "Model# 10. 727 nodes still misclassified \n",
      "\n",
      "Model# 11. 725 nodes still misclassified \n",
      "\n",
      "Model# 12. 610 nodes still misclassified \n",
      "\n",
      "Model# 13. 606 nodes still misclassified \n",
      "\n",
      "Model# 14. 581 nodes still misclassified \n",
      "\n",
      "Model# 15. 577 nodes still misclassified \n",
      "\n",
      "Model# 16. 538 nodes still misclassified \n",
      "\n",
      "Model# 17. 538 nodes still misclassified \n",
      "\n",
      "Model# 18. 537 nodes still misclassified \n",
      "\n",
      "Model# 19. 537 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68172/68172 [00:00<00:00, 1397677.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1309 nodes still misclassified \n",
      "\n",
      "Model# 1. 1168 nodes still misclassified \n",
      "\n",
      "Model# 2. 1150 nodes still misclassified \n",
      "\n",
      "Model# 3. 1124 nodes still misclassified \n",
      "\n",
      "Model# 4. 1093 nodes still misclassified \n",
      "\n",
      "Model# 5. 1055 nodes still misclassified \n",
      "\n",
      "Model# 6. 1040 nodes still misclassified \n",
      "\n",
      "Model# 7. 905 nodes still misclassified \n",
      "\n",
      "Model# 8. 784 nodes still misclassified \n",
      "\n",
      "Model# 9. 783 nodes still misclassified \n",
      "\n",
      "Model# 10. 782 nodes still misclassified \n",
      "\n",
      "Model# 11. 780 nodes still misclassified \n",
      "\n",
      "Model# 12. 779 nodes still misclassified \n",
      "\n",
      "Model# 13. 778 nodes still misclassified \n",
      "\n",
      "Model# 14. 778 nodes still misclassified \n",
      "\n",
      "Model# 15. 772 nodes still misclassified \n",
      "\n",
      "Model# 16. 770 nodes still misclassified \n",
      "\n",
      "Model# 17. 759 nodes still misclassified \n",
      "\n",
      "Model# 18. 754 nodes still misclassified \n",
      "\n",
      "Model# 19. 748 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68178/68178 [00:00<00:00, 1439824.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1089 nodes still misclassified \n",
      "\n",
      "Model# 1. 1059 nodes still misclassified \n",
      "\n",
      "Model# 2. 1050 nodes still misclassified \n",
      "\n",
      "Model# 3. 983 nodes still misclassified \n",
      "\n",
      "Model# 4. 928 nodes still misclassified \n",
      "\n",
      "Model# 5. 897 nodes still misclassified \n",
      "\n",
      "Model# 6. 882 nodes still misclassified \n",
      "\n",
      "Model# 7. 599 nodes still misclassified \n",
      "\n",
      "Model# 8. 577 nodes still misclassified \n",
      "\n",
      "Model# 9. 568 nodes still misclassified \n",
      "\n",
      "Model# 10. 567 nodes still misclassified \n",
      "\n",
      "Model# 11. 565 nodes still misclassified \n",
      "\n",
      "Model# 12. 564 nodes still misclassified \n",
      "\n",
      "Model# 13. 562 nodes still misclassified \n",
      "\n",
      "Model# 14. 559 nodes still misclassified \n",
      "\n",
      "Model# 15. 511 nodes still misclassified \n",
      "\n",
      "Model# 16. 477 nodes still misclassified \n",
      "\n",
      "Model# 17. 477 nodes still misclassified \n",
      "\n",
      "Model# 18. 477 nodes still misclassified \n",
      "\n",
      "Model# 19. 431 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68016/68016 [00:00<00:00, 1318310.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1843 nodes still misclassified \n",
      "\n",
      "Model# 1. 1761 nodes still misclassified \n",
      "\n",
      "Model# 2. 1646 nodes still misclassified \n",
      "\n",
      "Model# 3. 1550 nodes still misclassified \n",
      "\n",
      "Model# 4. 1393 nodes still misclassified \n",
      "\n",
      "Model# 5. 1359 nodes still misclassified \n",
      "\n",
      "Model# 6. 1348 nodes still misclassified \n",
      "\n",
      "Model# 7. 1340 nodes still misclassified \n",
      "\n",
      "Model# 8. 1222 nodes still misclassified \n",
      "\n",
      "Model# 9. 1220 nodes still misclassified \n",
      "\n",
      "Model# 10. 1213 nodes still misclassified \n",
      "\n",
      "Model# 11. 1213 nodes still misclassified \n",
      "\n",
      "Model# 12. 1211 nodes still misclassified \n",
      "\n",
      "Model# 13. 1208 nodes still misclassified \n",
      "\n",
      "Model# 14. 1200 nodes still misclassified \n",
      "\n",
      "Model# 15. 1185 nodes still misclassified \n",
      "\n",
      "Model# 16. 498 nodes still misclassified \n",
      "\n",
      "Model# 17. 498 nodes still misclassified \n",
      "\n",
      "Model# 18. 496 nodes still misclassified \n",
      "\n",
      "Model# 19. 496 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68070/68070 [00:00<00:00, 1430048.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1187 nodes still misclassified \n",
      "\n",
      "Model# 1. 1156 nodes still misclassified \n",
      "\n",
      "Model# 2. 1115 nodes still misclassified \n",
      "\n",
      "Model# 3. 1095 nodes still misclassified \n",
      "\n",
      "Model# 4. 1082 nodes still misclassified \n",
      "\n",
      "Model# 5. 1071 nodes still misclassified \n",
      "\n",
      "Model# 6. 1035 nodes still misclassified \n",
      "\n",
      "Model# 7. 915 nodes still misclassified \n",
      "\n",
      "Model# 8. 880 nodes still misclassified \n",
      "\n",
      "Model# 9. 867 nodes still misclassified \n",
      "\n",
      "Model# 10. 861 nodes still misclassified \n",
      "\n",
      "Model# 11. 860 nodes still misclassified \n",
      "\n",
      "Model# 12. 860 nodes still misclassified \n",
      "\n",
      "Model# 13. 591 nodes still misclassified \n",
      "\n",
      "Model# 14. 510 nodes still misclassified \n",
      "\n",
      "Model# 15. 509 nodes still misclassified \n",
      "\n",
      "Model# 16. 509 nodes still misclassified \n",
      "\n",
      "Model# 17. 509 nodes still misclassified \n",
      "\n",
      "Model# 18. 509 nodes still misclassified \n",
      "\n",
      "Model# 19. 509 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68053/68053 [00:00<00:00, 614084.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1629 nodes still misclassified \n",
      "\n",
      "Model# 1. 1603 nodes still misclassified \n",
      "\n",
      "Model# 2. 1590 nodes still misclassified \n",
      "\n",
      "Model# 3. 1581 nodes still misclassified \n",
      "\n",
      "Model# 4. 1554 nodes still misclassified \n",
      "\n",
      "Model# 5. 1495 nodes still misclassified \n",
      "\n",
      "Model# 6. 1488 nodes still misclassified \n",
      "\n",
      "Model# 7. 1482 nodes still misclassified \n",
      "\n",
      "Model# 8. 1422 nodes still misclassified \n",
      "\n",
      "Model# 9. 1409 nodes still misclassified \n",
      "\n",
      "Model# 10. 765 nodes still misclassified \n",
      "\n",
      "Model# 11. 762 nodes still misclassified \n",
      "\n",
      "Model# 12. 760 nodes still misclassified \n",
      "\n",
      "Model# 13. 760 nodes still misclassified \n",
      "\n",
      "Model# 14. 733 nodes still misclassified \n",
      "\n",
      "Model# 15. 729 nodes still misclassified \n",
      "\n",
      "Model# 16. 727 nodes still misclassified \n",
      "\n",
      "Model# 17. 726 nodes still misclassified \n",
      "\n",
      "Model# 18. 710 nodes still misclassified \n",
      "\n",
      "Model# 19. 540 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68154/68154 [00:00<00:00, 1364499.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1305 nodes still misclassified \n",
      "\n",
      "Model# 1. 1028 nodes still misclassified \n",
      "\n",
      "Model# 2. 801 nodes still misclassified \n",
      "\n",
      "Model# 3. 786 nodes still misclassified \n",
      "\n",
      "Model# 4. 699 nodes still misclassified \n",
      "\n",
      "Model# 5. 670 nodes still misclassified \n",
      "\n",
      "Model# 6. 655 nodes still misclassified \n",
      "\n",
      "Model# 7. 621 nodes still misclassified \n",
      "\n",
      "Model# 8. 619 nodes still misclassified \n",
      "\n",
      "Model# 9. 605 nodes still misclassified \n",
      "\n",
      "Model# 10. 359 nodes still misclassified \n",
      "\n",
      "Model# 11. 357 nodes still misclassified \n",
      "\n",
      "Model# 12. 355 nodes still misclassified \n",
      "\n",
      "Model# 13. 354 nodes still misclassified \n",
      "\n",
      "Model# 14. 354 nodes still misclassified \n",
      "\n",
      "Model# 15. 354 nodes still misclassified \n",
      "\n",
      "Model# 16. 354 nodes still misclassified \n",
      "\n",
      "Model# 17. 354 nodes still misclassified \n",
      "\n",
      "Model# 18. 354 nodes still misclassified \n",
      "\n",
      "Model# 19. 354 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68051/68051 [00:00<00:00, 1352841.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1966 nodes still misclassified \n",
      "\n",
      "Model# 1. 1891 nodes still misclassified \n",
      "\n",
      "Model# 2. 1784 nodes still misclassified \n",
      "\n",
      "Model# 3. 1704 nodes still misclassified \n",
      "\n",
      "Model# 4. 1655 nodes still misclassified \n",
      "\n",
      "Model# 5. 1639 nodes still misclassified \n",
      "\n",
      "Model# 6. 1587 nodes still misclassified \n",
      "\n",
      "Model# 7. 1570 nodes still misclassified \n",
      "\n",
      "Model# 8. 1563 nodes still misclassified \n",
      "\n",
      "Model# 9. 1560 nodes still misclassified \n",
      "\n",
      "Model# 10. 1472 nodes still misclassified \n",
      "\n",
      "Model# 11. 1463 nodes still misclassified \n",
      "\n",
      "Model# 12. 1455 nodes still misclassified \n",
      "\n",
      "Model# 13. 1453 nodes still misclassified \n",
      "\n",
      "Model# 14. 1445 nodes still misclassified \n",
      "\n",
      "Model# 15. 1443 nodes still misclassified \n",
      "\n",
      "Model# 16. 869 nodes still misclassified \n",
      "\n",
      "Model# 17. 868 nodes still misclassified \n",
      "\n",
      "Model# 18. 852 nodes still misclassified \n",
      "\n",
      "Model# 19. 837 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67951/67951 [00:00<00:00, 1332051.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1370 nodes still misclassified \n",
      "\n",
      "Model# 1. 1324 nodes still misclassified \n",
      "\n",
      "Model# 2. 1289 nodes still misclassified \n",
      "\n",
      "Model# 3. 1155 nodes still misclassified \n",
      "\n",
      "Model# 4. 1107 nodes still misclassified \n",
      "\n",
      "Model# 5. 962 nodes still misclassified \n",
      "\n",
      "Model# 6. 953 nodes still misclassified \n",
      "\n",
      "Model# 7. 941 nodes still misclassified \n",
      "\n",
      "Model# 8. 938 nodes still misclassified \n",
      "\n",
      "Model# 9. 864 nodes still misclassified \n",
      "\n",
      "Model# 10. 863 nodes still misclassified \n",
      "\n",
      "Model# 11. 805 nodes still misclassified \n",
      "\n",
      "Model# 12. 805 nodes still misclassified \n",
      "\n",
      "Model# 13. 606 nodes still misclassified \n",
      "\n",
      "Model# 14. 606 nodes still misclassified \n",
      "\n",
      "Model# 15. 604 nodes still misclassified \n",
      "\n",
      "Model# 16. 521 nodes still misclassified \n",
      "\n",
      "Model# 17. 521 nodes still misclassified \n",
      "\n",
      "Model# 18. 484 nodes still misclassified \n",
      "\n",
      "Model# 19. 479 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68081/68081 [00:00<00:00, 1371009.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1692 nodes still misclassified \n",
      "\n",
      "Model# 1. 1666 nodes still misclassified \n",
      "\n",
      "Model# 2. 1656 nodes still misclassified \n",
      "\n",
      "Model# 3. 1645 nodes still misclassified \n",
      "\n",
      "Model# 4. 1632 nodes still misclassified \n",
      "\n",
      "Model# 5. 1624 nodes still misclassified \n",
      "\n",
      "Model# 6. 1610 nodes still misclassified \n",
      "\n",
      "Model# 7. 1599 nodes still misclassified \n",
      "\n",
      "Model# 8. 691 nodes still misclassified \n",
      "\n",
      "Model# 9. 688 nodes still misclassified \n",
      "\n",
      "Model# 10. 540 nodes still misclassified \n",
      "\n",
      "Model# 11. 537 nodes still misclassified \n",
      "\n",
      "Model# 12. 536 nodes still misclassified \n",
      "\n",
      "Model# 13. 536 nodes still misclassified \n",
      "\n",
      "Model# 14. 533 nodes still misclassified \n",
      "\n",
      "Model# 15. 533 nodes still misclassified \n",
      "\n",
      "Model# 16. 531 nodes still misclassified \n",
      "\n",
      "Model# 17. 531 nodes still misclassified \n",
      "\n",
      "Model# 18. 531 nodes still misclassified \n",
      "\n",
      "Model# 19. 528 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68106/68106 [00:00<00:00, 1352294.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 953 nodes still misclassified \n",
      "\n",
      "Model# 1. 906 nodes still misclassified \n",
      "\n",
      "Model# 2. 873 nodes still misclassified \n",
      "\n",
      "Model# 3. 855 nodes still misclassified \n",
      "\n",
      "Model# 4. 835 nodes still misclassified \n",
      "\n",
      "Model# 5. 823 nodes still misclassified \n",
      "\n",
      "Model# 6. 688 nodes still misclassified \n",
      "\n",
      "Model# 7. 626 nodes still misclassified \n",
      "\n",
      "Model# 8. 530 nodes still misclassified \n",
      "\n",
      "Model# 9. 487 nodes still misclassified \n",
      "\n",
      "Model# 10. 487 nodes still misclassified \n",
      "\n",
      "Model# 11. 487 nodes still misclassified \n",
      "\n",
      "Model# 12. 487 nodes still misclassified \n",
      "\n",
      "Model# 13. 436 nodes still misclassified \n",
      "\n",
      "Model# 14. 386 nodes still misclassified \n",
      "\n",
      "Model# 15. 385 nodes still misclassified \n",
      "\n",
      "Model# 16. 385 nodes still misclassified \n",
      "\n",
      "Model# 17. 385 nodes still misclassified \n",
      "\n",
      "Model# 18. 375 nodes still misclassified \n",
      "\n",
      "Model# 19. 361 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68068/68068 [00:00<00:00, 1301895.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1522 nodes still misclassified \n",
      "\n",
      "Model# 1. 1511 nodes still misclassified \n",
      "\n",
      "Model# 2. 1481 nodes still misclassified \n",
      "\n",
      "Model# 3. 1395 nodes still misclassified \n",
      "\n",
      "Model# 4. 1366 nodes still misclassified \n",
      "\n",
      "Model# 5. 1079 nodes still misclassified \n",
      "\n",
      "Model# 6. 1066 nodes still misclassified \n",
      "\n",
      "Model# 7. 1057 nodes still misclassified \n",
      "\n",
      "Model# 8. 1057 nodes still misclassified \n",
      "\n",
      "Model# 9. 1041 nodes still misclassified \n",
      "\n",
      "Model# 10. 1006 nodes still misclassified \n",
      "\n",
      "Model# 11. 1005 nodes still misclassified \n",
      "\n",
      "Model# 12. 998 nodes still misclassified \n",
      "\n",
      "Model# 13. 993 nodes still misclassified \n",
      "\n",
      "Model# 14. 809 nodes still misclassified \n",
      "\n",
      "Model# 15. 806 nodes still misclassified \n",
      "\n",
      "Model# 16. 623 nodes still misclassified \n",
      "\n",
      "Model# 17. 440 nodes still misclassified \n",
      "\n",
      "Model# 18. 440 nodes still misclassified \n",
      "\n",
      "Model# 19. 440 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68032/68032 [00:00<00:00, 1300394.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1292 nodes still misclassified \n",
      "\n",
      "Model# 1. 1262 nodes still misclassified \n",
      "\n",
      "Model# 2. 1225 nodes still misclassified \n",
      "\n",
      "Model# 3. 862 nodes still misclassified \n",
      "\n",
      "Model# 4. 854 nodes still misclassified \n",
      "\n",
      "Model# 5. 839 nodes still misclassified \n",
      "\n",
      "Model# 6. 820 nodes still misclassified \n",
      "\n",
      "Model# 7. 741 nodes still misclassified \n",
      "\n",
      "Model# 8. 733 nodes still misclassified \n",
      "\n",
      "Model# 9. 729 nodes still misclassified \n",
      "\n",
      "Model# 10. 638 nodes still misclassified \n",
      "\n",
      "Model# 11. 623 nodes still misclassified \n",
      "\n",
      "Model# 12. 614 nodes still misclassified \n",
      "\n",
      "Model# 13. 612 nodes still misclassified \n",
      "\n",
      "Model# 14. 611 nodes still misclassified \n",
      "\n",
      "Model# 15. 559 nodes still misclassified \n",
      "\n",
      "Model# 16. 511 nodes still misclassified \n",
      "\n",
      "Model# 17. 511 nodes still misclassified \n",
      "\n",
      "Model# 18. 462 nodes still misclassified \n",
      "\n",
      "Model# 19. 462 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68145/68145 [00:00<00:00, 1203025.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1083 nodes still misclassified \n",
      "\n",
      "Model# 1. 1043 nodes still misclassified \n",
      "\n",
      "Model# 2. 935 nodes still misclassified \n",
      "\n",
      "Model# 3. 925 nodes still misclassified \n",
      "\n",
      "Model# 4. 877 nodes still misclassified \n",
      "\n",
      "Model# 5. 871 nodes still misclassified \n",
      "\n",
      "Model# 6. 866 nodes still misclassified \n",
      "\n",
      "Model# 7. 859 nodes still misclassified \n",
      "\n",
      "Model# 8. 854 nodes still misclassified \n",
      "\n",
      "Model# 9. 611 nodes still misclassified \n",
      "\n",
      "Model# 10. 611 nodes still misclassified \n",
      "\n",
      "Model# 11. 462 nodes still misclassified \n",
      "\n",
      "Model# 12. 459 nodes still misclassified \n",
      "\n",
      "Model# 13. 437 nodes still misclassified \n",
      "\n",
      "Model# 14. 436 nodes still misclassified \n",
      "\n",
      "Model# 15. 435 nodes still misclassified \n",
      "\n",
      "Model# 16. 434 nodes still misclassified \n",
      "\n",
      "Model# 17. 432 nodes still misclassified \n",
      "\n",
      "Model# 18. 414 nodes still misclassified \n",
      "\n",
      "Model# 19. 402 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68162/68162 [00:00<00:00, 684832.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1045 nodes still misclassified \n",
      "\n",
      "Model# 1. 934 nodes still misclassified \n",
      "\n",
      "Model# 2. 916 nodes still misclassified \n",
      "\n",
      "Model# 3. 868 nodes still misclassified \n",
      "\n",
      "Model# 4. 848 nodes still misclassified \n",
      "\n",
      "Model# 5. 824 nodes still misclassified \n",
      "\n",
      "Model# 6. 794 nodes still misclassified \n",
      "\n",
      "Model# 7. 788 nodes still misclassified \n",
      "\n",
      "Model# 8. 514 nodes still misclassified \n",
      "\n",
      "Model# 9. 510 nodes still misclassified \n",
      "\n",
      "Model# 10. 506 nodes still misclassified \n",
      "\n",
      "Model# 11. 505 nodes still misclassified \n",
      "\n",
      "Model# 12. 505 nodes still misclassified \n",
      "\n",
      "Model# 13. 437 nodes still misclassified \n",
      "\n",
      "Model# 14. 370 nodes still misclassified \n",
      "\n",
      "Model# 15. 370 nodes still misclassified \n",
      "\n",
      "Model# 16. 369 nodes still misclassified \n",
      "\n",
      "Model# 17. 369 nodes still misclassified \n",
      "\n",
      "Model# 18. 364 nodes still misclassified \n",
      "\n",
      "Model# 19. 364 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68144/68144 [00:00<00:00, 650833.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1273 nodes still misclassified \n",
      "\n",
      "Model# 1. 1089 nodes still misclassified \n",
      "\n",
      "Model# 2. 1083 nodes still misclassified \n",
      "\n",
      "Model# 3. 1082 nodes still misclassified \n",
      "\n",
      "Model# 4. 1081 nodes still misclassified \n",
      "\n",
      "Model# 5. 936 nodes still misclassified \n",
      "\n",
      "Model# 6. 932 nodes still misclassified \n",
      "\n",
      "Model# 7. 891 nodes still misclassified \n",
      "\n",
      "Model# 8. 890 nodes still misclassified \n",
      "\n",
      "Model# 9. 459 nodes still misclassified \n",
      "\n",
      "Model# 10. 458 nodes still misclassified \n",
      "\n",
      "Model# 11. 458 nodes still misclassified \n",
      "\n",
      "Model# 12. 456 nodes still misclassified \n",
      "\n",
      "Model# 13. 456 nodes still misclassified \n",
      "\n",
      "Model# 14. 456 nodes still misclassified \n",
      "\n",
      "Model# 15. 454 nodes still misclassified \n",
      "\n",
      "Model# 16. 454 nodes still misclassified \n",
      "\n",
      "Model# 17. 440 nodes still misclassified \n",
      "\n",
      "Model# 18. 434 nodes still misclassified \n",
      "\n",
      "Model# 19. 384 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68157/68157 [00:00<00:00, 1357522.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1278 nodes still misclassified \n",
      "\n",
      "Model# 1. 1239 nodes still misclassified \n",
      "\n",
      "Model# 2. 1144 nodes still misclassified \n",
      "\n",
      "Model# 3. 1128 nodes still misclassified \n",
      "\n",
      "Model# 4. 939 nodes still misclassified \n",
      "\n",
      "Model# 5. 741 nodes still misclassified \n",
      "\n",
      "Model# 6. 727 nodes still misclassified \n",
      "\n",
      "Model# 7. 597 nodes still misclassified \n",
      "\n",
      "Model# 8. 370 nodes still misclassified \n",
      "\n",
      "Model# 9. 370 nodes still misclassified \n",
      "\n",
      "Model# 10. 370 nodes still misclassified \n",
      "\n",
      "Model# 11. 369 nodes still misclassified \n",
      "\n",
      "Model# 12. 369 nodes still misclassified \n",
      "\n",
      "Model# 13. 369 nodes still misclassified \n",
      "\n",
      "Model# 14. 368 nodes still misclassified \n",
      "\n",
      "Model# 15. 368 nodes still misclassified \n",
      "\n",
      "Model# 16. 342 nodes still misclassified \n",
      "\n",
      "Model# 17. 342 nodes still misclassified \n",
      "\n",
      "Model# 18. 342 nodes still misclassified \n",
      "\n",
      "Model# 19. 342 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68064/68064 [00:00<00:00, 1397601.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1693 nodes still misclassified \n",
      "\n",
      "Model# 1. 1688 nodes still misclassified \n",
      "\n",
      "Model# 2. 1656 nodes still misclassified \n",
      "\n",
      "Model# 3. 1620 nodes still misclassified \n",
      "\n",
      "Model# 4. 1578 nodes still misclassified \n",
      "\n",
      "Model# 5. 1559 nodes still misclassified \n",
      "\n",
      "Model# 6. 1508 nodes still misclassified \n",
      "\n",
      "Model# 7. 1507 nodes still misclassified \n",
      "\n",
      "Model# 8. 1207 nodes still misclassified \n",
      "\n",
      "Model# 9. 1198 nodes still misclassified \n",
      "\n",
      "Model# 10. 1133 nodes still misclassified \n",
      "\n",
      "Model# 11. 1127 nodes still misclassified \n",
      "\n",
      "Model# 12. 830 nodes still misclassified \n",
      "\n",
      "Model# 13. 821 nodes still misclassified \n",
      "\n",
      "Model# 14. 810 nodes still misclassified \n",
      "\n",
      "Model# 15. 726 nodes still misclassified \n",
      "\n",
      "Model# 16. 703 nodes still misclassified \n",
      "\n",
      "Model# 17. 693 nodes still misclassified \n",
      "\n",
      "Model# 18. 689 nodes still misclassified \n",
      "\n",
      "Model# 19. 681 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68154/68154 [00:00<00:00, 1330534.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1276 nodes still misclassified \n",
      "\n",
      "Model# 1. 1194 nodes still misclassified \n",
      "\n",
      "Model# 2. 1061 nodes still misclassified \n",
      "\n",
      "Model# 3. 1038 nodes still misclassified \n",
      "\n",
      "Model# 4. 1023 nodes still misclassified \n",
      "\n",
      "Model# 5. 998 nodes still misclassified \n",
      "\n",
      "Model# 6. 985 nodes still misclassified \n",
      "\n",
      "Model# 7. 801 nodes still misclassified \n",
      "\n",
      "Model# 8. 795 nodes still misclassified \n",
      "\n",
      "Model# 9. 786 nodes still misclassified \n",
      "\n",
      "Model# 10. 783 nodes still misclassified \n",
      "\n",
      "Model# 11. 779 nodes still misclassified \n",
      "\n",
      "Model# 12. 777 nodes still misclassified \n",
      "\n",
      "Model# 13. 776 nodes still misclassified \n",
      "\n",
      "Model# 14. 776 nodes still misclassified \n",
      "\n",
      "Model# 15. 775 nodes still misclassified \n",
      "\n",
      "Model# 16. 690 nodes still misclassified \n",
      "\n",
      "Model# 17. 606 nodes still misclassified \n",
      "\n",
      "Model# 18. 603 nodes still misclassified \n",
      "\n",
      "Model# 19. 599 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68079/68079 [00:00<00:00, 1399094.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1347 nodes still misclassified \n",
      "\n",
      "Model# 1. 1073 nodes still misclassified \n",
      "\n",
      "Model# 2. 1071 nodes still misclassified \n",
      "\n",
      "Model# 3. 1015 nodes still misclassified \n",
      "\n",
      "Model# 4. 1013 nodes still misclassified \n",
      "\n",
      "Model# 5. 1010 nodes still misclassified \n",
      "\n",
      "Model# 6. 972 nodes still misclassified \n",
      "\n",
      "Model# 7. 834 nodes still misclassified \n",
      "\n",
      "Model# 8. 834 nodes still misclassified \n",
      "\n",
      "Model# 9. 699 nodes still misclassified \n",
      "\n",
      "Model# 10. 699 nodes still misclassified \n",
      "\n",
      "Model# 11. 699 nodes still misclassified \n",
      "\n",
      "Model# 12. 699 nodes still misclassified \n",
      "\n",
      "Model# 13. 698 nodes still misclassified \n",
      "\n",
      "Model# 14. 698 nodes still misclassified \n",
      "\n",
      "Model# 15. 698 nodes still misclassified \n",
      "\n",
      "Model# 16. 696 nodes still misclassified \n",
      "\n",
      "Model# 17. 685 nodes still misclassified \n",
      "\n",
      "Model# 18. 648 nodes still misclassified \n",
      "\n",
      "Model# 19. 644 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68146/68146 [00:00<00:00, 1237284.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1328 nodes still misclassified \n",
      "\n",
      "Model# 1. 994 nodes still misclassified \n",
      "\n",
      "Model# 2. 820 nodes still misclassified \n",
      "\n",
      "Model# 3. 711 nodes still misclassified \n",
      "\n",
      "Model# 4. 697 nodes still misclassified \n",
      "\n",
      "Model# 5. 673 nodes still misclassified \n",
      "\n",
      "Model# 6. 648 nodes still misclassified \n",
      "\n",
      "Model# 7. 637 nodes still misclassified \n",
      "\n",
      "Model# 8. 636 nodes still misclassified \n",
      "\n",
      "Model# 9. 634 nodes still misclassified \n",
      "\n",
      "Model# 10. 632 nodes still misclassified \n",
      "\n",
      "Model# 11. 578 nodes still misclassified \n",
      "\n",
      "Model# 12. 525 nodes still misclassified \n",
      "\n",
      "Model# 13. 524 nodes still misclassified \n",
      "\n",
      "Model# 14. 406 nodes still misclassified \n",
      "\n",
      "Model# 15. 406 nodes still misclassified \n",
      "\n",
      "Model# 16. 406 nodes still misclassified \n",
      "\n",
      "Model# 17. 405 nodes still misclassified \n",
      "\n",
      "Model# 18. 405 nodes still misclassified \n",
      "\n",
      "Model# 19. 394 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68058/68058 [00:00<00:00, 1326480.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 2300 nodes still misclassified \n",
      "\n",
      "Model# 1. 2232 nodes still misclassified \n",
      "\n",
      "Model# 2. 2073 nodes still misclassified \n",
      "\n",
      "Model# 3. 1812 nodes still misclassified \n",
      "\n",
      "Model# 4. 1336 nodes still misclassified \n",
      "\n",
      "Model# 5. 1254 nodes still misclassified \n",
      "\n",
      "Model# 6. 1253 nodes still misclassified \n",
      "\n",
      "Model# 7. 529 nodes still misclassified \n",
      "\n",
      "Model# 8. 527 nodes still misclassified \n",
      "\n",
      "Model# 9. 526 nodes still misclassified \n",
      "\n",
      "Model# 10. 488 nodes still misclassified \n",
      "\n",
      "Model# 11. 483 nodes still misclassified \n",
      "\n",
      "Model# 12. 482 nodes still misclassified \n",
      "\n",
      "Model# 13. 479 nodes still misclassified \n",
      "\n",
      "Model# 14. 464 nodes still misclassified \n",
      "\n",
      "Model# 15. 464 nodes still misclassified \n",
      "\n",
      "Model# 16. 464 nodes still misclassified \n",
      "\n",
      "Model# 17. 462 nodes still misclassified \n",
      "\n",
      "Model# 18. 461 nodes still misclassified \n",
      "\n",
      "Model# 19. 461 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68107/68107 [00:00<00:00, 1351591.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1397 nodes still misclassified \n",
      "\n",
      "Model# 1. 1381 nodes still misclassified \n",
      "\n",
      "Model# 2. 1244 nodes still misclassified \n",
      "\n",
      "Model# 3. 1174 nodes still misclassified \n",
      "\n",
      "Model# 4. 1139 nodes still misclassified \n",
      "\n",
      "Model# 5. 1027 nodes still misclassified \n",
      "\n",
      "Model# 6. 852 nodes still misclassified \n",
      "\n",
      "Model# 7. 695 nodes still misclassified \n",
      "\n",
      "Model# 8. 693 nodes still misclassified \n",
      "\n",
      "Model# 9. 687 nodes still misclassified \n",
      "\n",
      "Model# 10. 686 nodes still misclassified \n",
      "\n",
      "Model# 11. 666 nodes still misclassified \n",
      "\n",
      "Model# 12. 666 nodes still misclassified \n",
      "\n",
      "Model# 13. 660 nodes still misclassified \n",
      "\n",
      "Model# 14. 660 nodes still misclassified \n",
      "\n",
      "Model# 15. 646 nodes still misclassified \n",
      "\n",
      "Model# 16. 585 nodes still misclassified \n",
      "\n",
      "Model# 17. 584 nodes still misclassified \n",
      "\n",
      "Model# 18. 583 nodes still misclassified \n",
      "\n",
      "Model# 19. 581 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68134/68134 [00:00<00:00, 1279704.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 903 nodes still misclassified \n",
      "\n",
      "Model# 1. 845 nodes still misclassified \n",
      "\n",
      "Model# 2. 833 nodes still misclassified \n",
      "\n",
      "Model# 3. 829 nodes still misclassified \n",
      "\n",
      "Model# 4. 828 nodes still misclassified \n",
      "\n",
      "Model# 5. 825 nodes still misclassified \n",
      "\n",
      "Model# 6. 818 nodes still misclassified \n",
      "\n",
      "Model# 7. 814 nodes still misclassified \n",
      "\n",
      "Model# 8. 813 nodes still misclassified \n",
      "\n",
      "Model# 9. 811 nodes still misclassified \n",
      "\n",
      "Model# 10. 536 nodes still misclassified \n",
      "\n",
      "Model# 11. 536 nodes still misclassified \n",
      "\n",
      "Model# 12. 445 nodes still misclassified \n",
      "\n",
      "Model# 13. 445 nodes still misclassified \n",
      "\n",
      "Model# 14. 441 nodes still misclassified \n",
      "\n",
      "Model# 15. 418 nodes still misclassified \n",
      "\n",
      "Model# 16. 395 nodes still misclassified \n",
      "\n",
      "Model# 17. 395 nodes still misclassified \n",
      "\n",
      "Model# 18. 387 nodes still misclassified \n",
      "\n",
      "Model# 19. 387 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68104/68104 [00:00<00:00, 1343888.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1594 nodes still misclassified \n",
      "\n",
      "Model# 1. 1529 nodes still misclassified \n",
      "\n",
      "Model# 2. 1516 nodes still misclassified \n",
      "\n",
      "Model# 3. 1505 nodes still misclassified \n",
      "\n",
      "Model# 4. 1222 nodes still misclassified \n",
      "\n",
      "Model# 5. 872 nodes still misclassified \n",
      "\n",
      "Model# 6. 663 nodes still misclassified \n",
      "\n",
      "Model# 7. 652 nodes still misclassified \n",
      "\n",
      "Model# 8. 645 nodes still misclassified \n",
      "\n",
      "Model# 9. 641 nodes still misclassified \n",
      "\n",
      "Model# 10. 383 nodes still misclassified \n",
      "\n",
      "Model# 11. 383 nodes still misclassified \n",
      "\n",
      "Model# 12. 383 nodes still misclassified \n",
      "\n",
      "Model# 13. 383 nodes still misclassified \n",
      "\n",
      "Model# 14. 383 nodes still misclassified \n",
      "\n",
      "Model# 15. 383 nodes still misclassified \n",
      "\n",
      "Model# 16. 367 nodes still misclassified \n",
      "\n",
      "Model# 17. 367 nodes still misclassified \n",
      "\n",
      "Model# 18. 367 nodes still misclassified \n",
      "\n",
      "Model# 19. 367 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68172/68172 [00:00<00:00, 1350363.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1384 nodes still misclassified \n",
      "\n",
      "Model# 1. 1380 nodes still misclassified \n",
      "\n",
      "Model# 2. 1357 nodes still misclassified \n",
      "\n",
      "Model# 3. 1192 nodes still misclassified \n",
      "\n",
      "Model# 4. 1187 nodes still misclassified \n",
      "\n",
      "Model# 5. 1183 nodes still misclassified \n",
      "\n",
      "Model# 6. 1171 nodes still misclassified \n",
      "\n",
      "Model# 7. 1157 nodes still misclassified \n",
      "\n",
      "Model# 8. 953 nodes still misclassified \n",
      "\n",
      "Model# 9. 739 nodes still misclassified \n",
      "\n",
      "Model# 10. 709 nodes still misclassified \n",
      "\n",
      "Model# 11. 701 nodes still misclassified \n",
      "\n",
      "Model# 12. 701 nodes still misclassified \n",
      "\n",
      "Model# 13. 639 nodes still misclassified \n",
      "\n",
      "Model# 14. 639 nodes still misclassified \n",
      "\n",
      "Model# 15. 598 nodes still misclassified \n",
      "\n",
      "Model# 16. 596 nodes still misclassified \n",
      "\n",
      "Model# 17. 595 nodes still misclassified \n",
      "\n",
      "Model# 18. 581 nodes still misclassified \n",
      "\n",
      "Model# 19. 579 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58411/58411 [00:00<00:00, 1423015.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 2107 nodes still misclassified \n",
      "\n",
      "Model# 1. 1805 nodes still misclassified \n",
      "\n",
      "Model# 2. 1533 nodes still misclassified \n",
      "\n",
      "Model# 3. 1360 nodes still misclassified \n",
      "\n",
      "Model# 4. 963 nodes still misclassified \n",
      "\n",
      "Model# 5. 877 nodes still misclassified \n",
      "\n",
      "Model# 6. 861 nodes still misclassified \n",
      "\n",
      "Model# 7. 788 nodes still misclassified \n",
      "\n",
      "Model# 8. 781 nodes still misclassified \n",
      "\n",
      "Model# 9. 767 nodes still misclassified \n",
      "\n",
      "Model# 10. 402 nodes still misclassified \n",
      "\n",
      "Model# 11. 394 nodes still misclassified \n",
      "\n",
      "Model# 12. 387 nodes still misclassified \n",
      "\n",
      "Model# 13. 386 nodes still misclassified \n",
      "\n",
      "Model# 14. 386 nodes still misclassified \n",
      "\n",
      "Model# 15. 386 nodes still misclassified \n",
      "\n",
      "Model# 16. 386 nodes still misclassified \n",
      "\n",
      "Model# 17. 386 nodes still misclassified \n",
      "\n",
      "Model# 18. 386 nodes still misclassified \n",
      "\n",
      "Model# 19. 386 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58361/58361 [00:00<00:00, 1287062.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1105 nodes still misclassified \n",
      "\n",
      "Model# 1. 1031 nodes still misclassified \n",
      "\n",
      "Model# 2. 1011 nodes still misclassified \n",
      "\n",
      "Model# 3. 954 nodes still misclassified \n",
      "\n",
      "Model# 4. 942 nodes still misclassified \n",
      "\n",
      "Model# 5. 899 nodes still misclassified \n",
      "\n",
      "Model# 6. 896 nodes still misclassified \n",
      "\n",
      "Model# 7. 744 nodes still misclassified \n",
      "\n",
      "Model# 8. 579 nodes still misclassified \n",
      "\n",
      "Model# 9. 577 nodes still misclassified \n",
      "\n",
      "Model# 10. 576 nodes still misclassified \n",
      "\n",
      "Model# 11. 571 nodes still misclassified \n",
      "\n",
      "Model# 12. 571 nodes still misclassified \n",
      "\n",
      "Model# 13. 570 nodes still misclassified \n",
      "\n",
      "Model# 14. 528 nodes still misclassified \n",
      "\n",
      "Model# 15. 528 nodes still misclassified \n",
      "\n",
      "Model# 16. 509 nodes still misclassified \n",
      "\n",
      "Model# 17. 328 nodes still misclassified \n",
      "\n",
      "Model# 18. 326 nodes still misclassified \n",
      "\n",
      "Model# 19. 320 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58419/58419 [00:00<00:00, 1381274.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1079 nodes still misclassified \n",
      "\n",
      "Model# 1. 930 nodes still misclassified \n",
      "\n",
      "Model# 2. 814 nodes still misclassified \n",
      "\n",
      "Model# 3. 699 nodes still misclassified \n",
      "\n",
      "Model# 4. 663 nodes still misclassified \n",
      "\n",
      "Model# 5. 654 nodes still misclassified \n",
      "\n",
      "Model# 6. 639 nodes still misclassified \n",
      "\n",
      "Model# 7. 634 nodes still misclassified \n",
      "\n",
      "Model# 8. 631 nodes still misclassified \n",
      "\n",
      "Model# 9. 631 nodes still misclassified \n",
      "\n",
      "Model# 10. 629 nodes still misclassified \n",
      "\n",
      "Model# 11. 361 nodes still misclassified \n",
      "\n",
      "Model# 12. 360 nodes still misclassified \n",
      "\n",
      "Model# 13. 360 nodes still misclassified \n",
      "\n",
      "Model# 14. 360 nodes still misclassified \n",
      "\n",
      "Model# 15. 360 nodes still misclassified \n",
      "\n",
      "Model# 16. 360 nodes still misclassified \n",
      "\n",
      "Model# 17. 360 nodes still misclassified \n",
      "\n",
      "Model# 18. 357 nodes still misclassified \n",
      "\n",
      "Model# 19. 334 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58321/58321 [00:00<00:00, 1099071.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1005 nodes still misclassified \n",
      "\n",
      "Model# 1. 890 nodes still misclassified \n",
      "\n",
      "Model# 2. 877 nodes still misclassified \n",
      "\n",
      "Model# 3. 871 nodes still misclassified \n",
      "\n",
      "Model# 4. 863 nodes still misclassified \n",
      "\n",
      "Model# 5. 851 nodes still misclassified \n",
      "\n",
      "Model# 6. 845 nodes still misclassified \n",
      "\n",
      "Model# 7. 836 nodes still misclassified \n",
      "\n",
      "Model# 8. 819 nodes still misclassified \n",
      "\n",
      "Model# 9. 818 nodes still misclassified \n",
      "\n",
      "Model# 10. 706 nodes still misclassified \n",
      "\n",
      "Model# 11. 596 nodes still misclassified \n",
      "\n",
      "Model# 12. 449 nodes still misclassified \n",
      "\n",
      "Model# 13. 449 nodes still misclassified \n",
      "\n",
      "Model# 14. 447 nodes still misclassified \n",
      "\n",
      "Model# 15. 444 nodes still misclassified \n",
      "\n",
      "Model# 16. 444 nodes still misclassified \n",
      "\n",
      "Model# 17. 444 nodes still misclassified \n",
      "\n",
      "Model# 18. 428 nodes still misclassified \n",
      "\n",
      "Model# 19. 392 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58305/58305 [00:00<00:00, 674997.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1275 nodes still misclassified \n",
      "\n",
      "Model# 1. 1226 nodes still misclassified \n",
      "\n",
      "Model# 2. 1116 nodes still misclassified \n",
      "\n",
      "Model# 3. 1076 nodes still misclassified \n",
      "\n",
      "Model# 4. 996 nodes still misclassified \n",
      "\n",
      "Model# 5. 604 nodes still misclassified \n",
      "\n",
      "Model# 6. 576 nodes still misclassified \n",
      "\n",
      "Model# 7. 518 nodes still misclassified \n",
      "\n",
      "Model# 8. 496 nodes still misclassified \n",
      "\n",
      "Model# 9. 488 nodes still misclassified \n",
      "\n",
      "Model# 10. 486 nodes still misclassified \n",
      "\n",
      "Model# 11. 484 nodes still misclassified \n",
      "\n",
      "Model# 12. 484 nodes still misclassified \n",
      "\n",
      "Model# 13. 408 nodes still misclassified \n",
      "\n",
      "Model# 14. 406 nodes still misclassified \n",
      "\n",
      "Model# 15. 330 nodes still misclassified \n",
      "\n",
      "Model# 16. 330 nodes still misclassified \n",
      "\n",
      "Model# 17. 330 nodes still misclassified \n",
      "\n",
      "Model# 18. 330 nodes still misclassified \n",
      "\n",
      "Model# 19. 330 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68211/68211 [00:00<00:00, 643758.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 934 nodes still misclassified \n",
      "\n",
      "Model# 1. 929 nodes still misclassified \n",
      "\n",
      "Model# 2. 928 nodes still misclassified \n",
      "\n",
      "Model# 3. 926 nodes still misclassified \n",
      "\n",
      "Model# 4. 924 nodes still misclassified \n",
      "\n",
      "Model# 5. 924 nodes still misclassified \n",
      "\n",
      "Model# 6. 924 nodes still misclassified \n",
      "\n",
      "Model# 7. 923 nodes still misclassified \n",
      "\n",
      "Model# 8. 922 nodes still misclassified \n",
      "\n",
      "Model# 9. 749 nodes still misclassified \n",
      "\n",
      "Model# 10. 742 nodes still misclassified \n",
      "\n",
      "Model# 11. 740 nodes still misclassified \n",
      "\n",
      "Model# 12. 740 nodes still misclassified \n",
      "\n",
      "Model# 13. 609 nodes still misclassified \n",
      "\n",
      "Model# 14. 609 nodes still misclassified \n",
      "\n",
      "Model# 15. 605 nodes still misclassified \n",
      "\n",
      "Model# 16. 475 nodes still misclassified \n",
      "\n",
      "Model# 17. 472 nodes still misclassified \n",
      "\n",
      "Model# 18. 472 nodes still misclassified \n",
      "\n",
      "Model# 19. 472 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68038/68038 [00:00<00:00, 1364587.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1342 nodes still misclassified \n",
      "\n",
      "Model# 1. 1268 nodes still misclassified \n",
      "\n",
      "Model# 2. 1228 nodes still misclassified \n",
      "\n",
      "Model# 3. 1181 nodes still misclassified \n",
      "\n",
      "Model# 4. 1154 nodes still misclassified \n",
      "\n",
      "Model# 5. 1106 nodes still misclassified \n",
      "\n",
      "Model# 6. 1079 nodes still misclassified \n",
      "\n",
      "Model# 7. 964 nodes still misclassified \n",
      "\n",
      "Model# 8. 849 nodes still misclassified \n",
      "\n",
      "Model# 9. 834 nodes still misclassified \n",
      "\n",
      "Model# 10. 829 nodes still misclassified \n",
      "\n",
      "Model# 11. 779 nodes still misclassified \n",
      "\n",
      "Model# 12. 762 nodes still misclassified \n",
      "\n",
      "Model# 13. 752 nodes still misclassified \n",
      "\n",
      "Model# 14. 694 nodes still misclassified \n",
      "\n",
      "Model# 15. 694 nodes still misclassified \n",
      "\n",
      "Model# 16. 693 nodes still misclassified \n",
      "\n",
      "Model# 17. 692 nodes still misclassified \n",
      "\n",
      "Model# 18. 667 nodes still misclassified \n",
      "\n",
      "Model# 19. 650 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67935/67935 [00:00<00:00, 1129275.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1687 nodes still misclassified \n",
      "\n",
      "Model# 1. 1638 nodes still misclassified \n",
      "\n",
      "Model# 2. 1582 nodes still misclassified \n",
      "\n",
      "Model# 3. 887 nodes still misclassified \n",
      "\n",
      "Model# 4. 882 nodes still misclassified \n",
      "\n",
      "Model# 5. 878 nodes still misclassified \n",
      "\n",
      "Model# 6. 603 nodes still misclassified \n",
      "\n",
      "Model# 7. 589 nodes still misclassified \n",
      "\n",
      "Model# 8. 587 nodes still misclassified \n",
      "\n",
      "Model# 9. 585 nodes still misclassified \n",
      "\n",
      "Model# 10. 525 nodes still misclassified \n",
      "\n",
      "Model# 11. 513 nodes still misclassified \n",
      "\n",
      "Model# 12. 510 nodes still misclassified \n",
      "\n",
      "Model# 13. 510 nodes still misclassified \n",
      "\n",
      "Model# 14. 508 nodes still misclassified \n",
      "\n",
      "Model# 15. 508 nodes still misclassified \n",
      "\n",
      "Model# 16. 486 nodes still misclassified \n",
      "\n",
      "Model# 17. 486 nodes still misclassified \n",
      "\n",
      "Model# 18. 485 nodes still misclassified \n",
      "\n",
      "Model# 19. 484 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58447/58447 [00:00<00:00, 1399066.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 794 nodes still misclassified \n",
      "\n",
      "Model# 1. 621 nodes still misclassified \n",
      "\n",
      "Model# 2. 601 nodes still misclassified \n",
      "\n",
      "Model# 3. 442 nodes still misclassified \n",
      "\n",
      "Model# 4. 428 nodes still misclassified \n",
      "\n",
      "Model# 5. 424 nodes still misclassified \n",
      "\n",
      "Model# 6. 417 nodes still misclassified \n",
      "\n",
      "Model# 7. 415 nodes still misclassified \n",
      "\n",
      "Model# 8. 333 nodes still misclassified \n",
      "\n",
      "Model# 9. 253 nodes still misclassified \n",
      "\n",
      "Model# 10. 250 nodes still misclassified \n",
      "\n",
      "Model# 11. 247 nodes still misclassified \n",
      "\n",
      "Model# 12. 247 nodes still misclassified \n",
      "\n",
      "Model# 13. 247 nodes still misclassified \n",
      "\n",
      "Model# 14. 245 nodes still misclassified \n",
      "\n",
      "Model# 15. 245 nodes still misclassified \n",
      "\n",
      "Model# 16. 245 nodes still misclassified \n",
      "\n",
      "Model# 17. 245 nodes still misclassified \n",
      "\n",
      "Model# 18. 245 nodes still misclassified \n",
      "\n",
      "Model# 19. 226 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68079/68079 [00:00<00:00, 1310923.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1136 nodes still misclassified \n",
      "\n",
      "Model# 1. 1124 nodes still misclassified \n",
      "\n",
      "Model# 2. 1122 nodes still misclassified \n",
      "\n",
      "Model# 3. 1115 nodes still misclassified \n",
      "\n",
      "Model# 4. 1115 nodes still misclassified \n",
      "\n",
      "Model# 5. 1114 nodes still misclassified \n",
      "\n",
      "Model# 6. 1111 nodes still misclassified \n",
      "\n",
      "Model# 7. 1095 nodes still misclassified \n",
      "\n",
      "Model# 8. 1057 nodes still misclassified \n",
      "\n",
      "Model# 9. 1052 nodes still misclassified \n",
      "\n",
      "Model# 10. 1041 nodes still misclassified \n",
      "\n",
      "Model# 11. 1032 nodes still misclassified \n",
      "\n",
      "Model# 12. 586 nodes still misclassified \n",
      "\n",
      "Model# 13. 583 nodes still misclassified \n",
      "\n",
      "Model# 14. 582 nodes still misclassified \n",
      "\n",
      "Model# 15. 582 nodes still misclassified \n",
      "\n",
      "Model# 16. 581 nodes still misclassified \n",
      "\n",
      "Model# 17. 519 nodes still misclassified \n",
      "\n",
      "Model# 18. 519 nodes still misclassified \n",
      "\n",
      "Model# 19. 515 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58256/58256 [00:00<00:00, 1239667.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1292 nodes still misclassified \n",
      "\n",
      "Model# 1. 1216 nodes still misclassified \n",
      "\n",
      "Model# 2. 1093 nodes still misclassified \n",
      "\n",
      "Model# 3. 1029 nodes still misclassified \n",
      "\n",
      "Model# 4. 977 nodes still misclassified \n",
      "\n",
      "Model# 5. 958 nodes still misclassified \n",
      "\n",
      "Model# 6. 947 nodes still misclassified \n",
      "\n",
      "Model# 7. 945 nodes still misclassified \n",
      "\n",
      "Model# 8. 692 nodes still misclassified \n",
      "\n",
      "Model# 9. 541 nodes still misclassified \n",
      "\n",
      "Model# 10. 540 nodes still misclassified \n",
      "\n",
      "Model# 11. 531 nodes still misclassified \n",
      "\n",
      "Model# 12. 530 nodes still misclassified \n",
      "\n",
      "Model# 13. 530 nodes still misclassified \n",
      "\n",
      "Model# 14. 525 nodes still misclassified \n",
      "\n",
      "Model# 15. 481 nodes still misclassified \n",
      "\n",
      "Model# 16. 476 nodes still misclassified \n",
      "\n",
      "Model# 17. 433 nodes still misclassified \n",
      "\n",
      "Model# 18. 433 nodes still misclassified \n",
      "\n",
      "Model# 19. 430 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58438/58438 [00:00<00:00, 1291047.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1007 nodes still misclassified \n",
      "\n",
      "Model# 1. 988 nodes still misclassified \n",
      "\n",
      "Model# 2. 983 nodes still misclassified \n",
      "\n",
      "Model# 3. 941 nodes still misclassified \n",
      "\n",
      "Model# 4. 935 nodes still misclassified \n",
      "\n",
      "Model# 5. 928 nodes still misclassified \n",
      "\n",
      "Model# 6. 902 nodes still misclassified \n",
      "\n",
      "Model# 7. 856 nodes still misclassified \n",
      "\n",
      "Model# 8. 847 nodes still misclassified \n",
      "\n",
      "Model# 9. 804 nodes still misclassified \n",
      "\n",
      "Model# 10. 760 nodes still misclassified \n",
      "\n",
      "Model# 11. 511 nodes still misclassified \n",
      "\n",
      "Model# 12. 283 nodes still misclassified \n",
      "\n",
      "Model# 13. 283 nodes still misclassified \n",
      "\n",
      "Model# 14. 282 nodes still misclassified \n",
      "\n",
      "Model# 15. 281 nodes still misclassified \n",
      "\n",
      "Model# 16. 281 nodes still misclassified \n",
      "\n",
      "Model# 17. 281 nodes still misclassified \n",
      "\n",
      "Model# 18. 281 nodes still misclassified \n",
      "\n",
      "Model# 19. 281 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58433/58433 [00:00<00:00, 1372299.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 932 nodes still misclassified \n",
      "\n",
      "Model# 1. 882 nodes still misclassified \n",
      "\n",
      "Model# 2. 857 nodes still misclassified \n",
      "\n",
      "Model# 3. 845 nodes still misclassified \n",
      "\n",
      "Model# 4. 842 nodes still misclassified \n",
      "\n",
      "Model# 5. 835 nodes still misclassified \n",
      "\n",
      "Model# 6. 835 nodes still misclassified \n",
      "\n",
      "Model# 7. 835 nodes still misclassified \n",
      "\n",
      "Model# 8. 826 nodes still misclassified \n",
      "\n",
      "Model# 9. 820 nodes still misclassified \n",
      "\n",
      "Model# 10. 819 nodes still misclassified \n",
      "\n",
      "Model# 11. 747 nodes still misclassified \n",
      "\n",
      "Model# 12. 746 nodes still misclassified \n",
      "\n",
      "Model# 13. 728 nodes still misclassified \n",
      "\n",
      "Model# 14. 503 nodes still misclassified \n",
      "\n",
      "Model# 15. 499 nodes still misclassified \n",
      "\n",
      "Model# 16. 498 nodes still misclassified \n",
      "\n",
      "Model# 17. 487 nodes still misclassified \n",
      "\n",
      "Model# 18. 462 nodes still misclassified \n",
      "\n",
      "Model# 19. 460 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58449/58449 [00:00<00:00, 1377526.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 729 nodes still misclassified \n",
      "\n",
      "Model# 1. 669 nodes still misclassified \n",
      "\n",
      "Model# 2. 659 nodes still misclassified \n",
      "\n",
      "Model# 3. 644 nodes still misclassified \n",
      "\n",
      "Model# 4. 601 nodes still misclassified \n",
      "\n",
      "Model# 5. 597 nodes still misclassified \n",
      "\n",
      "Model# 6. 564 nodes still misclassified \n",
      "\n",
      "Model# 7. 559 nodes still misclassified \n",
      "\n",
      "Model# 8. 525 nodes still misclassified \n",
      "\n",
      "Model# 9. 506 nodes still misclassified \n",
      "\n",
      "Model# 10. 502 nodes still misclassified \n",
      "\n",
      "Model# 11. 498 nodes still misclassified \n",
      "\n",
      "Model# 12. 402 nodes still misclassified \n",
      "\n",
      "Model# 13. 402 nodes still misclassified \n",
      "\n",
      "Model# 14. 348 nodes still misclassified \n",
      "\n",
      "Model# 15. 287 nodes still misclassified \n",
      "\n",
      "Model# 16. 286 nodes still misclassified \n",
      "\n",
      "Model# 17. 282 nodes still misclassified \n",
      "\n",
      "Model# 18. 280 nodes still misclassified \n",
      "\n",
      "Model# 19. 280 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58327/58327 [00:00<00:00, 1310722.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1916 nodes still misclassified \n",
      "\n",
      "Model# 1. 1901 nodes still misclassified \n",
      "\n",
      "Model# 2. 1474 nodes still misclassified \n",
      "\n",
      "Model# 3. 1419 nodes still misclassified \n",
      "\n",
      "Model# 4. 1364 nodes still misclassified \n",
      "\n",
      "Model# 5. 947 nodes still misclassified \n",
      "\n",
      "Model# 6. 913 nodes still misclassified \n",
      "\n",
      "Model# 7. 835 nodes still misclassified \n",
      "\n",
      "Model# 8. 809 nodes still misclassified \n",
      "\n",
      "Model# 9. 684 nodes still misclassified \n",
      "\n",
      "Model# 10. 403 nodes still misclassified \n",
      "\n",
      "Model# 11. 399 nodes still misclassified \n",
      "\n",
      "Model# 12. 399 nodes still misclassified \n",
      "\n",
      "Model# 13. 399 nodes still misclassified \n",
      "\n",
      "Model# 14. 399 nodes still misclassified \n",
      "\n",
      "Model# 15. 399 nodes still misclassified \n",
      "\n",
      "Model# 16. 399 nodes still misclassified \n",
      "\n",
      "Model# 17. 398 nodes still misclassified \n",
      "\n",
      "Model# 18. 398 nodes still misclassified \n",
      "\n",
      "Model# 19. 398 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58320/58320 [00:00<00:00, 1407481.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1029 nodes still misclassified \n",
      "\n",
      "Model# 1. 1013 nodes still misclassified \n",
      "\n",
      "Model# 2. 1005 nodes still misclassified \n",
      "\n",
      "Model# 3. 999 nodes still misclassified \n",
      "\n",
      "Model# 4. 982 nodes still misclassified \n",
      "\n",
      "Model# 5. 979 nodes still misclassified \n",
      "\n",
      "Model# 6. 568 nodes still misclassified \n",
      "\n",
      "Model# 7. 561 nodes still misclassified \n",
      "\n",
      "Model# 8. 549 nodes still misclassified \n",
      "\n",
      "Model# 9. 542 nodes still misclassified \n",
      "\n",
      "Model# 10. 542 nodes still misclassified \n",
      "\n",
      "Model# 11. 540 nodes still misclassified \n",
      "\n",
      "Model# 12. 520 nodes still misclassified \n",
      "\n",
      "Model# 13. 486 nodes still misclassified \n",
      "\n",
      "Model# 14. 485 nodes still misclassified \n",
      "\n",
      "Model# 15. 478 nodes still misclassified \n",
      "\n",
      "Model# 16. 473 nodes still misclassified \n",
      "\n",
      "Model# 17. 471 nodes still misclassified \n",
      "\n",
      "Model# 18. 470 nodes still misclassified \n",
      "\n",
      "Model# 19. 424 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58304/58304 [00:00<00:00, 1239663.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1255 nodes still misclassified \n",
      "\n",
      "Model# 1. 1211 nodes still misclassified \n",
      "\n",
      "Model# 2. 1147 nodes still misclassified \n",
      "\n",
      "Model# 3. 1135 nodes still misclassified \n",
      "\n",
      "Model# 4. 1079 nodes still misclassified \n",
      "\n",
      "Model# 5. 918 nodes still misclassified \n",
      "\n",
      "Model# 6. 880 nodes still misclassified \n",
      "\n",
      "Model# 7. 868 nodes still misclassified \n",
      "\n",
      "Model# 8. 830 nodes still misclassified \n",
      "\n",
      "Model# 9. 807 nodes still misclassified \n",
      "\n",
      "Model# 10. 803 nodes still misclassified \n",
      "\n",
      "Model# 11. 694 nodes still misclassified \n",
      "\n",
      "Model# 12. 589 nodes still misclassified \n",
      "\n",
      "Model# 13. 435 nodes still misclassified \n",
      "\n",
      "Model# 14. 435 nodes still misclassified \n",
      "\n",
      "Model# 15. 434 nodes still misclassified \n",
      "\n",
      "Model# 16. 434 nodes still misclassified \n",
      "\n",
      "Model# 17. 434 nodes still misclassified \n",
      "\n",
      "Model# 18. 434 nodes still misclassified \n",
      "\n",
      "Model# 19. 434 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58340/58340 [00:00<00:00, 1377535.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 759 nodes still misclassified \n",
      "\n",
      "Model# 1. 735 nodes still misclassified \n",
      "\n",
      "Model# 2. 720 nodes still misclassified \n",
      "\n",
      "Model# 3. 709 nodes still misclassified \n",
      "\n",
      "Model# 4. 694 nodes still misclassified \n",
      "\n",
      "Model# 5. 686 nodes still misclassified \n",
      "\n",
      "Model# 6. 685 nodes still misclassified \n",
      "\n",
      "Model# 7. 684 nodes still misclassified \n",
      "\n",
      "Model# 8. 555 nodes still misclassified \n",
      "\n",
      "Model# 9. 555 nodes still misclassified \n",
      "\n",
      "Model# 10. 553 nodes still misclassified \n",
      "\n",
      "Model# 11. 553 nodes still misclassified \n",
      "\n",
      "Model# 12. 553 nodes still misclassified \n",
      "\n",
      "Model# 13. 553 nodes still misclassified \n",
      "\n",
      "Model# 14. 553 nodes still misclassified \n",
      "\n",
      "Model# 15. 553 nodes still misclassified \n",
      "\n",
      "Model# 16. 553 nodes still misclassified \n",
      "\n",
      "Model# 17. 548 nodes still misclassified \n",
      "\n",
      "Model# 18. 547 nodes still misclassified \n",
      "\n",
      "Model# 19. 508 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58465/58465 [00:00<00:00, 1398109.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1068 nodes still misclassified \n",
      "\n",
      "Model# 1. 678 nodes still misclassified \n",
      "\n",
      "Model# 2. 588 nodes still misclassified \n",
      "\n",
      "Model# 3. 533 nodes still misclassified \n",
      "\n",
      "Model# 4. 391 nodes still misclassified \n",
      "\n",
      "Model# 5. 388 nodes still misclassified \n",
      "\n",
      "Model# 6. 385 nodes still misclassified \n",
      "\n",
      "Model# 7. 381 nodes still misclassified \n",
      "\n",
      "Model# 8. 377 nodes still misclassified \n",
      "\n",
      "Model# 9. 374 nodes still misclassified \n",
      "\n",
      "Model# 10. 367 nodes still misclassified \n",
      "\n",
      "Model# 11. 366 nodes still misclassified \n",
      "\n",
      "Model# 12. 350 nodes still misclassified \n",
      "\n",
      "Model# 13. 333 nodes still misclassified \n",
      "\n",
      "Model# 14. 317 nodes still misclassified \n",
      "\n",
      "Model# 15. 282 nodes still misclassified \n",
      "\n",
      "Model# 16. 280 nodes still misclassified \n",
      "\n",
      "Model# 17. 256 nodes still misclassified \n",
      "\n",
      "Model# 18. 256 nodes still misclassified \n",
      "\n",
      "Model# 19. 256 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58290/58290 [00:00<00:00, 1346770.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1273 nodes still misclassified \n",
      "\n",
      "Model# 1. 1257 nodes still misclassified \n",
      "\n",
      "Model# 2. 1233 nodes still misclassified \n",
      "\n",
      "Model# 3. 1201 nodes still misclassified \n",
      "\n",
      "Model# 4. 1186 nodes still misclassified \n",
      "\n",
      "Model# 5. 1172 nodes still misclassified \n",
      "\n",
      "Model# 6. 729 nodes still misclassified \n",
      "\n",
      "Model# 7. 707 nodes still misclassified \n",
      "\n",
      "Model# 8. 699 nodes still misclassified \n",
      "\n",
      "Model# 9. 695 nodes still misclassified \n",
      "\n",
      "Model# 10. 686 nodes still misclassified \n",
      "\n",
      "Model# 11. 533 nodes still misclassified \n",
      "\n",
      "Model# 12. 531 nodes still misclassified \n",
      "\n",
      "Model# 13. 358 nodes still misclassified \n",
      "\n",
      "Model# 14. 356 nodes still misclassified \n",
      "\n",
      "Model# 15. 355 nodes still misclassified \n",
      "\n",
      "Model# 16. 354 nodes still misclassified \n",
      "\n",
      "Model# 17. 354 nodes still misclassified \n",
      "\n",
      "Model# 18. 353 nodes still misclassified \n",
      "\n",
      "Model# 19. 353 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58412/58412 [00:00<00:00, 1298221.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 810 nodes still misclassified \n",
      "\n",
      "Model# 1. 798 nodes still misclassified \n",
      "\n",
      "Model# 2. 796 nodes still misclassified \n",
      "\n",
      "Model# 3. 780 nodes still misclassified \n",
      "\n",
      "Model# 4. 780 nodes still misclassified \n",
      "\n",
      "Model# 5. 775 nodes still misclassified \n",
      "\n",
      "Model# 6. 773 nodes still misclassified \n",
      "\n",
      "Model# 7. 769 nodes still misclassified \n",
      "\n",
      "Model# 8. 766 nodes still misclassified \n",
      "\n",
      "Model# 9. 765 nodes still misclassified \n",
      "\n",
      "Model# 10. 611 nodes still misclassified \n",
      "\n",
      "Model# 11. 597 nodes still misclassified \n",
      "\n",
      "Model# 12. 442 nodes still misclassified \n",
      "\n",
      "Model# 13. 427 nodes still misclassified \n",
      "\n",
      "Model# 14. 422 nodes still misclassified \n",
      "\n",
      "Model# 15. 422 nodes still misclassified \n",
      "\n",
      "Model# 16. 421 nodes still misclassified \n",
      "\n",
      "Model# 17. 345 nodes still misclassified \n",
      "\n",
      "Model# 18. 330 nodes still misclassified \n",
      "\n",
      "Model# 19. 330 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58406/58406 [00:00<00:00, 1410149.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 958 nodes still misclassified \n",
      "\n",
      "Model# 1. 879 nodes still misclassified \n",
      "\n",
      "Model# 2. 842 nodes still misclassified \n",
      "\n",
      "Model# 3. 803 nodes still misclassified \n",
      "\n",
      "Model# 4. 789 nodes still misclassified \n",
      "\n",
      "Model# 5. 762 nodes still misclassified \n",
      "\n",
      "Model# 6. 751 nodes still misclassified \n",
      "\n",
      "Model# 7. 648 nodes still misclassified \n",
      "\n",
      "Model# 8. 631 nodes still misclassified \n",
      "\n",
      "Model# 9. 628 nodes still misclassified \n",
      "\n",
      "Model# 10. 625 nodes still misclassified \n",
      "\n",
      "Model# 11. 623 nodes still misclassified \n",
      "\n",
      "Model# 12. 547 nodes still misclassified \n",
      "\n",
      "Model# 13. 466 nodes still misclassified \n",
      "\n",
      "Model# 14. 463 nodes still misclassified \n",
      "\n",
      "Model# 15. 427 nodes still misclassified \n",
      "\n",
      "Model# 16. 409 nodes still misclassified \n",
      "\n",
      "Model# 17. 391 nodes still misclassified \n",
      "\n",
      "Model# 18. 389 nodes still misclassified \n",
      "\n",
      "Model# 19. 386 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58303/58303 [00:00<00:00, 1321012.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1278 nodes still misclassified \n",
      "\n",
      "Model# 1. 1256 nodes still misclassified \n",
      "\n",
      "Model# 2. 1200 nodes still misclassified \n",
      "\n",
      "Model# 3. 1197 nodes still misclassified \n",
      "\n",
      "Model# 4. 1186 nodes still misclassified \n",
      "\n",
      "Model# 5. 1176 nodes still misclassified \n",
      "\n",
      "Model# 6. 1172 nodes still misclassified \n",
      "\n",
      "Model# 7. 1167 nodes still misclassified \n",
      "\n",
      "Model# 8. 1156 nodes still misclassified \n",
      "\n",
      "Model# 9. 843 nodes still misclassified \n",
      "\n",
      "Model# 10. 837 nodes still misclassified \n",
      "\n",
      "Model# 11. 643 nodes still misclassified \n",
      "\n",
      "Model# 12. 601 nodes still misclassified \n",
      "\n",
      "Model# 13. 590 nodes still misclassified \n",
      "\n",
      "Model# 14. 529 nodes still misclassified \n",
      "\n",
      "Model# 15. 373 nodes still misclassified \n",
      "\n",
      "Model# 16. 373 nodes still misclassified \n",
      "\n",
      "Model# 17. 373 nodes still misclassified \n",
      "\n",
      "Model# 18. 373 nodes still misclassified \n",
      "\n",
      "Model# 19. 373 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58403/58403 [00:00<00:00, 1398412.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1461 nodes still misclassified \n",
      "\n",
      "Model# 1. 1436 nodes still misclassified \n",
      "\n",
      "Model# 2. 1393 nodes still misclassified \n",
      "\n",
      "Model# 3. 1346 nodes still misclassified \n",
      "\n",
      "Model# 4. 1322 nodes still misclassified \n",
      "\n",
      "Model# 5. 1054 nodes still misclassified \n",
      "\n",
      "Model# 6. 781 nodes still misclassified \n",
      "\n",
      "Model# 7. 765 nodes still misclassified \n",
      "\n",
      "Model# 8. 587 nodes still misclassified \n",
      "\n",
      "Model# 9. 576 nodes still misclassified \n",
      "\n",
      "Model# 10. 543 nodes still misclassified \n",
      "\n",
      "Model# 11. 465 nodes still misclassified \n",
      "\n",
      "Model# 12. 378 nodes still misclassified \n",
      "\n",
      "Model# 13. 370 nodes still misclassified \n",
      "\n",
      "Model# 14. 369 nodes still misclassified \n",
      "\n",
      "Model# 15. 368 nodes still misclassified \n",
      "\n",
      "Model# 16. 366 nodes still misclassified \n",
      "\n",
      "Model# 17. 364 nodes still misclassified \n",
      "\n",
      "Model# 18. 362 nodes still misclassified \n",
      "\n",
      "Model# 19. 357 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58410/58410 [00:00<00:00, 1317019.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 837 nodes still misclassified \n",
      "\n",
      "Model# 1. 829 nodes still misclassified \n",
      "\n",
      "Model# 2. 796 nodes still misclassified \n",
      "\n",
      "Model# 3. 749 nodes still misclassified \n",
      "\n",
      "Model# 4. 747 nodes still misclassified \n",
      "\n",
      "Model# 5. 731 nodes still misclassified \n",
      "\n",
      "Model# 6. 725 nodes still misclassified \n",
      "\n",
      "Model# 7. 706 nodes still misclassified \n",
      "\n",
      "Model# 8. 702 nodes still misclassified \n",
      "\n",
      "Model# 9. 699 nodes still misclassified \n",
      "\n",
      "Model# 10. 693 nodes still misclassified \n",
      "\n",
      "Model# 11. 692 nodes still misclassified \n",
      "\n",
      "Model# 12. 692 nodes still misclassified \n",
      "\n",
      "Model# 13. 692 nodes still misclassified \n",
      "\n",
      "Model# 14. 437 nodes still misclassified \n",
      "\n",
      "Model# 15. 436 nodes still misclassified \n",
      "\n",
      "Model# 16. 435 nodes still misclassified \n",
      "\n",
      "Model# 17. 435 nodes still misclassified \n",
      "\n",
      "Model# 18. 435 nodes still misclassified \n",
      "\n",
      "Model# 19. 434 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58270/58270 [00:00<00:00, 1236058.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1075 nodes still misclassified \n",
      "\n",
      "Model# 1. 1049 nodes still misclassified \n",
      "\n",
      "Model# 2. 1046 nodes still misclassified \n",
      "\n",
      "Model# 3. 1011 nodes still misclassified \n",
      "\n",
      "Model# 4. 1004 nodes still misclassified \n",
      "\n",
      "Model# 5. 993 nodes still misclassified \n",
      "\n",
      "Model# 6. 990 nodes still misclassified \n",
      "\n",
      "Model# 7. 990 nodes still misclassified \n",
      "\n",
      "Model# 8. 990 nodes still misclassified \n",
      "\n",
      "Model# 9. 990 nodes still misclassified \n",
      "\n",
      "Model# 10. 990 nodes still misclassified \n",
      "\n",
      "Model# 11. 921 nodes still misclassified \n",
      "\n",
      "Model# 12. 919 nodes still misclassified \n",
      "\n",
      "Model# 13. 907 nodes still misclassified \n",
      "\n",
      "Model# 14. 761 nodes still misclassified \n",
      "\n",
      "Model# 15. 736 nodes still misclassified \n",
      "\n",
      "Model# 16. 732 nodes still misclassified \n",
      "\n",
      "Model# 17. 685 nodes still misclassified \n",
      "\n",
      "Model# 18. 494 nodes still misclassified \n",
      "\n",
      "Model# 19. 487 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48678/48678 [00:00<00:00, 1339102.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 981 nodes still misclassified \n",
      "\n",
      "Model# 1. 884 nodes still misclassified \n",
      "\n",
      "Model# 2. 870 nodes still misclassified \n",
      "\n",
      "Model# 3. 851 nodes still misclassified \n",
      "\n",
      "Model# 4. 664 nodes still misclassified \n",
      "\n",
      "Model# 5. 479 nodes still misclassified \n",
      "\n",
      "Model# 6. 477 nodes still misclassified \n",
      "\n",
      "Model# 7. 477 nodes still misclassified \n",
      "\n",
      "Model# 8. 473 nodes still misclassified \n",
      "\n",
      "Model# 9. 473 nodes still misclassified \n",
      "\n",
      "Model# 10. 473 nodes still misclassified \n",
      "\n",
      "Model# 11. 373 nodes still misclassified \n",
      "\n",
      "Model# 12. 372 nodes still misclassified \n",
      "\n",
      "Model# 13. 297 nodes still misclassified \n",
      "\n",
      "Model# 14. 294 nodes still misclassified \n",
      "\n",
      "Model# 15. 294 nodes still misclassified \n",
      "\n",
      "Model# 16. 294 nodes still misclassified \n",
      "\n",
      "Model# 17. 294 nodes still misclassified \n",
      "\n",
      "Model# 18. 287 nodes still misclassified \n",
      "\n",
      "Model# 19. 286 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48749/48749 [00:00<00:00, 1246452.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 946 nodes still misclassified \n",
      "\n",
      "Model# 1. 931 nodes still misclassified \n",
      "\n",
      "Model# 2. 924 nodes still misclassified \n",
      "\n",
      "Model# 3. 747 nodes still misclassified \n",
      "\n",
      "Model# 4. 561 nodes still misclassified \n",
      "\n",
      "Model# 5. 557 nodes still misclassified \n",
      "\n",
      "Model# 6. 552 nodes still misclassified \n",
      "\n",
      "Model# 7. 544 nodes still misclassified \n",
      "\n",
      "Model# 8. 438 nodes still misclassified \n",
      "\n",
      "Model# 9. 434 nodes still misclassified \n",
      "\n",
      "Model# 10. 433 nodes still misclassified \n",
      "\n",
      "Model# 11. 432 nodes still misclassified \n",
      "\n",
      "Model# 12. 431 nodes still misclassified \n",
      "\n",
      "Model# 13. 266 nodes still misclassified \n",
      "\n",
      "Model# 14. 261 nodes still misclassified \n",
      "\n",
      "Model# 15. 261 nodes still misclassified \n",
      "\n",
      "Model# 16. 259 nodes still misclassified \n",
      "\n",
      "Model# 17. 259 nodes still misclassified \n",
      "\n",
      "Model# 18. 258 nodes still misclassified \n",
      "\n",
      "Model# 19. 258 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48637/48637 [00:00<00:00, 1346781.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 819 nodes still misclassified \n",
      "\n",
      "Model# 1. 815 nodes still misclassified \n",
      "\n",
      "Model# 2. 799 nodes still misclassified \n",
      "\n",
      "Model# 3. 712 nodes still misclassified \n",
      "\n",
      "Model# 4. 708 nodes still misclassified \n",
      "\n",
      "Model# 5. 702 nodes still misclassified \n",
      "\n",
      "Model# 6. 700 nodes still misclassified \n",
      "\n",
      "Model# 7. 580 nodes still misclassified \n",
      "\n",
      "Model# 8. 461 nodes still misclassified \n",
      "\n",
      "Model# 9. 459 nodes still misclassified \n",
      "\n",
      "Model# 10. 459 nodes still misclassified \n",
      "\n",
      "Model# 11. 455 nodes still misclassified \n",
      "\n",
      "Model# 12. 453 nodes still misclassified \n",
      "\n",
      "Model# 13. 399 nodes still misclassified \n",
      "\n",
      "Model# 14. 371 nodes still misclassified \n",
      "\n",
      "Model# 15. 370 nodes still misclassified \n",
      "\n",
      "Model# 16. 326 nodes still misclassified \n",
      "\n",
      "Model# 17. 312 nodes still misclassified \n",
      "\n",
      "Model# 18. 293 nodes still misclassified \n",
      "\n",
      "Model# 19. 289 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48739/48739 [00:00<00:00, 1398034.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1730 nodes still misclassified \n",
      "\n",
      "Model# 1. 1567 nodes still misclassified \n",
      "\n",
      "Model# 2. 1262 nodes still misclassified \n",
      "\n",
      "Model# 3. 904 nodes still misclassified \n",
      "\n",
      "Model# 4. 667 nodes still misclassified \n",
      "\n",
      "Model# 5. 601 nodes still misclassified \n",
      "\n",
      "Model# 6. 549 nodes still misclassified \n",
      "\n",
      "Model# 7. 412 nodes still misclassified \n",
      "\n",
      "Model# 8. 403 nodes still misclassified \n",
      "\n",
      "Model# 9. 394 nodes still misclassified \n",
      "\n",
      "Model# 10. 382 nodes still misclassified \n",
      "\n",
      "Model# 11. 382 nodes still misclassified \n",
      "\n",
      "Model# 12. 378 nodes still misclassified \n",
      "\n",
      "Model# 13. 377 nodes still misclassified \n",
      "\n",
      "Model# 14. 214 nodes still misclassified \n",
      "\n",
      "Model# 15. 213 nodes still misclassified \n",
      "\n",
      "Model# 16. 213 nodes still misclassified \n",
      "\n",
      "Model# 17. 213 nodes still misclassified \n",
      "\n",
      "Model# 18. 212 nodes still misclassified \n",
      "\n",
      "Model# 19. 212 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48597/48597 [00:00<00:00, 1336199.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1283 nodes still misclassified \n",
      "\n",
      "Model# 1. 1198 nodes still misclassified \n",
      "\n",
      "Model# 2. 1051 nodes still misclassified \n",
      "\n",
      "Model# 3. 1046 nodes still misclassified \n",
      "\n",
      "Model# 4. 1041 nodes still misclassified \n",
      "\n",
      "Model# 5. 1036 nodes still misclassified \n",
      "\n",
      "Model# 6. 1031 nodes still misclassified \n",
      "\n",
      "Model# 7. 817 nodes still misclassified \n",
      "\n",
      "Model# 8. 816 nodes still misclassified \n",
      "\n",
      "Model# 9. 810 nodes still misclassified \n",
      "\n",
      "Model# 10. 594 nodes still misclassified \n",
      "\n",
      "Model# 11. 570 nodes still misclassified \n",
      "\n",
      "Model# 12. 569 nodes still misclassified \n",
      "\n",
      "Model# 13. 560 nodes still misclassified \n",
      "\n",
      "Model# 14. 560 nodes still misclassified \n",
      "\n",
      "Model# 15. 560 nodes still misclassified \n",
      "\n",
      "Model# 16. 560 nodes still misclassified \n",
      "\n",
      "Model# 17. 560 nodes still misclassified \n",
      "\n",
      "Model# 18. 559 nodes still misclassified \n",
      "\n",
      "Model# 19. 559 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48783/48783 [00:00<00:00, 1467932.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1388 nodes still misclassified \n",
      "\n",
      "Model# 1. 1378 nodes still misclassified \n",
      "\n",
      "Model# 2. 1316 nodes still misclassified \n",
      "\n",
      "Model# 3. 1275 nodes still misclassified \n",
      "\n",
      "Model# 4. 1074 nodes still misclassified \n",
      "\n",
      "Model# 5. 943 nodes still misclassified \n",
      "\n",
      "Model# 6. 679 nodes still misclassified \n",
      "\n",
      "Model# 7. 631 nodes still misclassified \n",
      "\n",
      "Model# 8. 601 nodes still misclassified \n",
      "\n",
      "Model# 9. 570 nodes still misclassified \n",
      "\n",
      "Model# 10. 570 nodes still misclassified \n",
      "\n",
      "Model# 11. 565 nodes still misclassified \n",
      "\n",
      "Model# 12. 456 nodes still misclassified \n",
      "\n",
      "Model# 13. 280 nodes still misclassified \n",
      "\n",
      "Model# 14. 280 nodes still misclassified \n",
      "\n",
      "Model# 15. 278 nodes still misclassified \n",
      "\n",
      "Model# 16. 278 nodes still misclassified \n",
      "\n",
      "Model# 17. 278 nodes still misclassified \n",
      "\n",
      "Model# 18. 278 nodes still misclassified \n",
      "\n",
      "Model# 19. 278 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48648/48648 [00:00<00:00, 1434175.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1083 nodes still misclassified \n",
      "\n",
      "Model# 1. 1043 nodes still misclassified \n",
      "\n",
      "Model# 2. 986 nodes still misclassified \n",
      "\n",
      "Model# 3. 901 nodes still misclassified \n",
      "\n",
      "Model# 4. 896 nodes still misclassified \n",
      "\n",
      "Model# 5. 895 nodes still misclassified \n",
      "\n",
      "Model# 6. 895 nodes still misclassified \n",
      "\n",
      "Model# 7. 895 nodes still misclassified \n",
      "\n",
      "Model# 8. 882 nodes still misclassified \n",
      "\n",
      "Model# 9. 846 nodes still misclassified \n",
      "\n",
      "Model# 10. 722 nodes still misclassified \n",
      "\n",
      "Model# 11. 714 nodes still misclassified \n",
      "\n",
      "Model# 12. 705 nodes still misclassified \n",
      "\n",
      "Model# 13. 540 nodes still misclassified \n",
      "\n",
      "Model# 14. 540 nodes still misclassified \n",
      "\n",
      "Model# 15. 540 nodes still misclassified \n",
      "\n",
      "Model# 16. 532 nodes still misclassified \n",
      "\n",
      "Model# 17. 532 nodes still misclassified \n",
      "\n",
      "Model# 18. 532 nodes still misclassified \n",
      "\n",
      "Model# 19. 379 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48524/48524 [00:00<00:00, 1299503.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1092 nodes still misclassified \n",
      "\n",
      "Model# 1. 1017 nodes still misclassified \n",
      "\n",
      "Model# 2. 901 nodes still misclassified \n",
      "\n",
      "Model# 3. 866 nodes still misclassified \n",
      "\n",
      "Model# 4. 860 nodes still misclassified \n",
      "\n",
      "Model# 5. 758 nodes still misclassified \n",
      "\n",
      "Model# 6. 744 nodes still misclassified \n",
      "\n",
      "Model# 7. 739 nodes still misclassified \n",
      "\n",
      "Model# 8. 732 nodes still misclassified \n",
      "\n",
      "Model# 9. 722 nodes still misclassified \n",
      "\n",
      "Model# 10. 719 nodes still misclassified \n",
      "\n",
      "Model# 11. 714 nodes still misclassified \n",
      "\n",
      "Model# 12. 710 nodes still misclassified \n",
      "\n",
      "Model# 13. 545 nodes still misclassified \n",
      "\n",
      "Model# 14. 544 nodes still misclassified \n",
      "\n",
      "Model# 15. 543 nodes still misclassified \n",
      "\n",
      "Model# 16. 527 nodes still misclassified \n",
      "\n",
      "Model# 17. 527 nodes still misclassified \n",
      "\n",
      "Model# 18. 525 nodes still misclassified \n",
      "\n",
      "Model# 19. 525 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48684/48684 [00:00<00:00, 1356194.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 697 nodes still misclassified \n",
      "\n",
      "Model# 1. 685 nodes still misclassified \n",
      "\n",
      "Model# 2. 660 nodes still misclassified \n",
      "\n",
      "Model# 3. 642 nodes still misclassified \n",
      "\n",
      "Model# 4. 613 nodes still misclassified \n",
      "\n",
      "Model# 5. 608 nodes still misclassified \n",
      "\n",
      "Model# 6. 565 nodes still misclassified \n",
      "\n",
      "Model# 7. 560 nodes still misclassified \n",
      "\n",
      "Model# 8. 361 nodes still misclassified \n",
      "\n",
      "Model# 9. 353 nodes still misclassified \n",
      "\n",
      "Model# 10. 348 nodes still misclassified \n",
      "\n",
      "Model# 11. 347 nodes still misclassified \n",
      "\n",
      "Model# 12. 342 nodes still misclassified \n",
      "\n",
      "Model# 13. 271 nodes still misclassified \n",
      "\n",
      "Model# 14. 270 nodes still misclassified \n",
      "\n",
      "Model# 15. 241 nodes still misclassified \n",
      "\n",
      "Model# 16. 240 nodes still misclassified \n",
      "\n",
      "Model# 17. 240 nodes still misclassified \n",
      "\n",
      "Model# 18. 240 nodes still misclassified \n",
      "\n",
      "Model# 19. 240 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48710/48710 [00:00<00:00, 1454974.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 561 nodes still misclassified \n",
      "\n",
      "Model# 1. 539 nodes still misclassified \n",
      "\n",
      "Model# 2. 533 nodes still misclassified \n",
      "\n",
      "Model# 3. 531 nodes still misclassified \n",
      "\n",
      "Model# 4. 517 nodes still misclassified \n",
      "\n",
      "Model# 5. 427 nodes still misclassified \n",
      "\n",
      "Model# 6. 373 nodes still misclassified \n",
      "\n",
      "Model# 7. 373 nodes still misclassified \n",
      "\n",
      "Model# 8. 372 nodes still misclassified \n",
      "\n",
      "Model# 9. 370 nodes still misclassified \n",
      "\n",
      "Model# 10. 274 nodes still misclassified \n",
      "\n",
      "Model# 11. 274 nodes still misclassified \n",
      "\n",
      "Model# 12. 274 nodes still misclassified \n",
      "\n",
      "Model# 13. 273 nodes still misclassified \n",
      "\n",
      "Model# 14. 273 nodes still misclassified \n",
      "\n",
      "Model# 15. 258 nodes still misclassified \n",
      "\n",
      "Model# 16. 256 nodes still misclassified \n",
      "\n",
      "Model# 17. 236 nodes still misclassified \n",
      "\n",
      "Model# 18. 235 nodes still misclassified \n",
      "\n",
      "Model# 19. 235 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48486/48486 [00:00<00:00, 1388327.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1264 nodes still misclassified \n",
      "\n",
      "Model# 1. 1236 nodes still misclassified \n",
      "\n",
      "Model# 2. 1211 nodes still misclassified \n",
      "\n",
      "Model# 3. 1155 nodes still misclassified \n",
      "\n",
      "Model# 4. 978 nodes still misclassified \n",
      "\n",
      "Model# 5. 959 nodes still misclassified \n",
      "\n",
      "Model# 6. 871 nodes still misclassified \n",
      "\n",
      "Model# 7. 770 nodes still misclassified \n",
      "\n",
      "Model# 8. 545 nodes still misclassified \n",
      "\n",
      "Model# 9. 521 nodes still misclassified \n",
      "\n",
      "Model# 10. 499 nodes still misclassified \n",
      "\n",
      "Model# 11. 496 nodes still misclassified \n",
      "\n",
      "Model# 12. 493 nodes still misclassified \n",
      "\n",
      "Model# 13. 488 nodes still misclassified \n",
      "\n",
      "Model# 14. 487 nodes still misclassified \n",
      "\n",
      "Model# 15. 449 nodes still misclassified \n",
      "\n",
      "Model# 16. 448 nodes still misclassified \n",
      "\n",
      "Model# 17. 425 nodes still misclassified \n",
      "\n",
      "Model# 18. 410 nodes still misclassified \n",
      "\n",
      "Model# 19. 370 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48646/48646 [00:00<00:00, 1454097.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 658 nodes still misclassified \n",
      "\n",
      "Model# 1. 585 nodes still misclassified \n",
      "\n",
      "Model# 2. 571 nodes still misclassified \n",
      "\n",
      "Model# 3. 569 nodes still misclassified \n",
      "\n",
      "Model# 4. 564 nodes still misclassified \n",
      "\n",
      "Model# 5. 558 nodes still misclassified \n",
      "\n",
      "Model# 6. 553 nodes still misclassified \n",
      "\n",
      "Model# 7. 547 nodes still misclassified \n",
      "\n",
      "Model# 8. 543 nodes still misclassified \n",
      "\n",
      "Model# 9. 402 nodes still misclassified \n",
      "\n",
      "Model# 10. 402 nodes still misclassified \n",
      "\n",
      "Model# 11. 343 nodes still misclassified \n",
      "\n",
      "Model# 12. 342 nodes still misclassified \n",
      "\n",
      "Model# 13. 338 nodes still misclassified \n",
      "\n",
      "Model# 14. 322 nodes still misclassified \n",
      "\n",
      "Model# 15. 320 nodes still misclassified \n",
      "\n",
      "Model# 16. 320 nodes still misclassified \n",
      "\n",
      "Model# 17. 313 nodes still misclassified \n",
      "\n",
      "Model# 18. 283 nodes still misclassified \n",
      "\n",
      "Model# 19. 283 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48615/48615 [00:00<00:00, 1424293.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1412 nodes still misclassified \n",
      "\n",
      "Model# 1. 1002 nodes still misclassified \n",
      "\n",
      "Model# 2. 891 nodes still misclassified \n",
      "\n",
      "Model# 3. 840 nodes still misclassified \n",
      "\n",
      "Model# 4. 794 nodes still misclassified \n",
      "\n",
      "Model# 5. 753 nodes still misclassified \n",
      "\n",
      "Model# 6. 622 nodes still misclassified \n",
      "\n",
      "Model# 7. 569 nodes still misclassified \n",
      "\n",
      "Model# 8. 549 nodes still misclassified \n",
      "\n",
      "Model# 9. 511 nodes still misclassified \n",
      "\n",
      "Model# 10. 505 nodes still misclassified \n",
      "\n",
      "Model# 11. 502 nodes still misclassified \n",
      "\n",
      "Model# 12. 501 nodes still misclassified \n",
      "\n",
      "Model# 13. 384 nodes still misclassified \n",
      "\n",
      "Model# 14. 379 nodes still misclassified \n",
      "\n",
      "Model# 15. 378 nodes still misclassified \n",
      "\n",
      "Model# 16. 376 nodes still misclassified \n",
      "\n",
      "Model# 17. 340 nodes still misclassified \n",
      "\n",
      "Model# 18. 337 nodes still misclassified \n",
      "\n",
      "Model# 19. 300 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48752/48752 [00:00<00:00, 1312608.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 831 nodes still misclassified \n",
      "\n",
      "Model# 1. 795 nodes still misclassified \n",
      "\n",
      "Model# 2. 759 nodes still misclassified \n",
      "\n",
      "Model# 3. 730 nodes still misclassified \n",
      "\n",
      "Model# 4. 723 nodes still misclassified \n",
      "\n",
      "Model# 5. 715 nodes still misclassified \n",
      "\n",
      "Model# 6. 714 nodes still misclassified \n",
      "\n",
      "Model# 7. 519 nodes still misclassified \n",
      "\n",
      "Model# 8. 516 nodes still misclassified \n",
      "\n",
      "Model# 9. 356 nodes still misclassified \n",
      "\n",
      "Model# 10. 333 nodes still misclassified \n",
      "\n",
      "Model# 11. 333 nodes still misclassified \n",
      "\n",
      "Model# 12. 333 nodes still misclassified \n",
      "\n",
      "Model# 13. 333 nodes still misclassified \n",
      "\n",
      "Model# 14. 271 nodes still misclassified \n",
      "\n",
      "Model# 15. 271 nodes still misclassified \n",
      "\n",
      "Model# 16. 271 nodes still misclassified \n",
      "\n",
      "Model# 17. 271 nodes still misclassified \n",
      "\n",
      "Model# 18. 271 nodes still misclassified \n",
      "\n",
      "Model# 19. 271 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48624/48624 [00:00<00:00, 1452157.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1074 nodes still misclassified \n",
      "\n",
      "Model# 1. 990 nodes still misclassified \n",
      "\n",
      "Model# 2. 890 nodes still misclassified \n",
      "\n",
      "Model# 3. 818 nodes still misclassified \n",
      "\n",
      "Model# 4. 806 nodes still misclassified \n",
      "\n",
      "Model# 5. 694 nodes still misclassified \n",
      "\n",
      "Model# 6. 623 nodes still misclassified \n",
      "\n",
      "Model# 7. 609 nodes still misclassified \n",
      "\n",
      "Model# 8. 591 nodes still misclassified \n",
      "\n",
      "Model# 9. 572 nodes still misclassified \n",
      "\n",
      "Model# 10. 549 nodes still misclassified \n",
      "\n",
      "Model# 11. 540 nodes still misclassified \n",
      "\n",
      "Model# 12. 539 nodes still misclassified \n",
      "\n",
      "Model# 13. 450 nodes still misclassified \n",
      "\n",
      "Model# 14. 450 nodes still misclassified \n",
      "\n",
      "Model# 15. 448 nodes still misclassified \n",
      "\n",
      "Model# 16. 448 nodes still misclassified \n",
      "\n",
      "Model# 17. 382 nodes still misclassified \n",
      "\n",
      "Model# 18. 364 nodes still misclassified \n",
      "\n",
      "Model# 19. 300 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48533/48533 [00:00<00:00, 1317571.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1318 nodes still misclassified \n",
      "\n",
      "Model# 1. 1300 nodes still misclassified \n",
      "\n",
      "Model# 2. 1292 nodes still misclassified \n",
      "\n",
      "Model# 3. 1287 nodes still misclassified \n",
      "\n",
      "Model# 4. 1271 nodes still misclassified \n",
      "\n",
      "Model# 5. 1265 nodes still misclassified \n",
      "\n",
      "Model# 6. 1264 nodes still misclassified \n",
      "\n",
      "Model# 7. 1030 nodes still misclassified \n",
      "\n",
      "Model# 8. 773 nodes still misclassified \n",
      "\n",
      "Model# 9. 765 nodes still misclassified \n",
      "\n",
      "Model# 10. 748 nodes still misclassified \n",
      "\n",
      "Model# 11. 687 nodes still misclassified \n",
      "\n",
      "Model# 12. 665 nodes still misclassified \n",
      "\n",
      "Model# 13. 662 nodes still misclassified \n",
      "\n",
      "Model# 14. 521 nodes still misclassified \n",
      "\n",
      "Model# 15. 519 nodes still misclassified \n",
      "\n",
      "Model# 16. 517 nodes still misclassified \n",
      "\n",
      "Model# 17. 500 nodes still misclassified \n",
      "\n",
      "Model# 18. 435 nodes still misclassified \n",
      "\n",
      "Model# 19. 435 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48646/48646 [00:00<00:00, 1426476.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 930 nodes still misclassified \n",
      "\n",
      "Model# 1. 904 nodes still misclassified \n",
      "\n",
      "Model# 2. 888 nodes still misclassified \n",
      "\n",
      "Model# 3. 860 nodes still misclassified \n",
      "\n",
      "Model# 4. 646 nodes still misclassified \n",
      "\n",
      "Model# 5. 633 nodes still misclassified \n",
      "\n",
      "Model# 6. 603 nodes still misclassified \n",
      "\n",
      "Model# 7. 570 nodes still misclassified \n",
      "\n",
      "Model# 8. 425 nodes still misclassified \n",
      "\n",
      "Model# 9. 396 nodes still misclassified \n",
      "\n",
      "Model# 10. 320 nodes still misclassified \n",
      "\n",
      "Model# 11. 296 nodes still misclassified \n",
      "\n",
      "Model# 12. 277 nodes still misclassified \n",
      "\n",
      "Model# 13. 277 nodes still misclassified \n",
      "\n",
      "Model# 14. 275 nodes still misclassified \n",
      "\n",
      "Model# 15. 274 nodes still misclassified \n",
      "\n",
      "Model# 16. 272 nodes still misclassified \n",
      "\n",
      "Model# 17. 272 nodes still misclassified \n",
      "\n",
      "Model# 18. 272 nodes still misclassified \n",
      "\n",
      "Model# 19. 272 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48612/48612 [00:00<00:00, 1383200.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 644 nodes still misclassified \n",
      "\n",
      "Model# 1. 546 nodes still misclassified \n",
      "\n",
      "Model# 2. 534 nodes still misclassified \n",
      "\n",
      "Model# 3. 518 nodes still misclassified \n",
      "\n",
      "Model# 4. 518 nodes still misclassified \n",
      "\n",
      "Model# 5. 516 nodes still misclassified \n",
      "\n",
      "Model# 6. 514 nodes still misclassified \n",
      "\n",
      "Model# 7. 451 nodes still misclassified \n",
      "\n",
      "Model# 8. 450 nodes still misclassified \n",
      "\n",
      "Model# 9. 450 nodes still misclassified \n",
      "\n",
      "Model# 10. 450 nodes still misclassified \n",
      "\n",
      "Model# 11. 449 nodes still misclassified \n",
      "\n",
      "Model# 12. 370 nodes still misclassified \n",
      "\n",
      "Model# 13. 370 nodes still misclassified \n",
      "\n",
      "Model# 14. 370 nodes still misclassified \n",
      "\n",
      "Model# 15. 370 nodes still misclassified \n",
      "\n",
      "Model# 16. 369 nodes still misclassified \n",
      "\n",
      "Model# 17. 366 nodes still misclassified \n",
      "\n",
      "Model# 18. 366 nodes still misclassified \n",
      "\n",
      "Model# 19. 366 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48749/48749 [00:00<00:00, 1319021.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1299 nodes still misclassified \n",
      "\n",
      "Model# 1. 1227 nodes still misclassified \n",
      "\n",
      "Model# 2. 1091 nodes still misclassified \n",
      "\n",
      "Model# 3. 903 nodes still misclassified \n",
      "\n",
      "Model# 4. 842 nodes still misclassified \n",
      "\n",
      "Model# 5. 649 nodes still misclassified \n",
      "\n",
      "Model# 6. 636 nodes still misclassified \n",
      "\n",
      "Model# 7. 624 nodes still misclassified \n",
      "\n",
      "Model# 8. 616 nodes still misclassified \n",
      "\n",
      "Model# 9. 421 nodes still misclassified \n",
      "\n",
      "Model# 10. 362 nodes still misclassified \n",
      "\n",
      "Model# 11. 354 nodes still misclassified \n",
      "\n",
      "Model# 12. 352 nodes still misclassified \n",
      "\n",
      "Model# 13. 341 nodes still misclassified \n",
      "\n",
      "Model# 14. 327 nodes still misclassified \n",
      "\n",
      "Model# 15. 324 nodes still misclassified \n",
      "\n",
      "Model# 16. 322 nodes still misclassified \n",
      "\n",
      "Model# 17. 321 nodes still misclassified \n",
      "\n",
      "Model# 18. 321 nodes still misclassified \n",
      "\n",
      "Model# 19. 321 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48536/48536 [00:00<00:00, 1366080.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1078 nodes still misclassified \n",
      "\n",
      "Model# 1. 1009 nodes still misclassified \n",
      "\n",
      "Model# 2. 901 nodes still misclassified \n",
      "\n",
      "Model# 3. 856 nodes still misclassified \n",
      "\n",
      "Model# 4. 840 nodes still misclassified \n",
      "\n",
      "Model# 5. 833 nodes still misclassified \n",
      "\n",
      "Model# 6. 811 nodes still misclassified \n",
      "\n",
      "Model# 7. 800 nodes still misclassified \n",
      "\n",
      "Model# 8. 744 nodes still misclassified \n",
      "\n",
      "Model# 9. 512 nodes still misclassified \n",
      "\n",
      "Model# 10. 509 nodes still misclassified \n",
      "\n",
      "Model# 11. 508 nodes still misclassified \n",
      "\n",
      "Model# 12. 507 nodes still misclassified \n",
      "\n",
      "Model# 13. 376 nodes still misclassified \n",
      "\n",
      "Model# 14. 357 nodes still misclassified \n",
      "\n",
      "Model# 15. 356 nodes still misclassified \n",
      "\n",
      "Model# 16. 353 nodes still misclassified \n",
      "\n",
      "Model# 17. 352 nodes still misclassified \n",
      "\n",
      "Model# 18. 350 nodes still misclassified \n",
      "\n",
      "Model# 19. 350 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48550/48550 [00:00<00:00, 1308588.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 848 nodes still misclassified \n",
      "\n",
      "Model# 1. 833 nodes still misclassified \n",
      "\n",
      "Model# 2. 824 nodes still misclassified \n",
      "\n",
      "Model# 3. 812 nodes still misclassified \n",
      "\n",
      "Model# 4. 799 nodes still misclassified \n",
      "\n",
      "Model# 5. 785 nodes still misclassified \n",
      "\n",
      "Model# 6. 774 nodes still misclassified \n",
      "\n",
      "Model# 7. 763 nodes still misclassified \n",
      "\n",
      "Model# 8. 756 nodes still misclassified \n",
      "\n",
      "Model# 9. 746 nodes still misclassified \n",
      "\n",
      "Model# 10. 668 nodes still misclassified \n",
      "\n",
      "Model# 11. 637 nodes still misclassified \n",
      "\n",
      "Model# 12. 626 nodes still misclassified \n",
      "\n",
      "Model# 13. 612 nodes still misclassified \n",
      "\n",
      "Model# 14. 607 nodes still misclassified \n",
      "\n",
      "Model# 15. 547 nodes still misclassified \n",
      "\n",
      "Model# 16. 484 nodes still misclassified \n",
      "\n",
      "Model# 17. 484 nodes still misclassified \n",
      "\n",
      "Model# 18. 482 nodes still misclassified \n",
      "\n",
      "Model# 19. 482 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48640/48640 [00:00<00:00, 1364776.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 761 nodes still misclassified \n",
      "\n",
      "Model# 1. 635 nodes still misclassified \n",
      "\n",
      "Model# 2. 625 nodes still misclassified \n",
      "\n",
      "Model# 3. 554 nodes still misclassified \n",
      "\n",
      "Model# 4. 545 nodes still misclassified \n",
      "\n",
      "Model# 5. 542 nodes still misclassified \n",
      "\n",
      "Model# 6. 538 nodes still misclassified \n",
      "\n",
      "Model# 7. 534 nodes still misclassified \n",
      "\n",
      "Model# 8. 439 nodes still misclassified \n",
      "\n",
      "Model# 9. 436 nodes still misclassified \n",
      "\n",
      "Model# 10. 321 nodes still misclassified \n",
      "\n",
      "Model# 11. 316 nodes still misclassified \n",
      "\n",
      "Model# 12. 314 nodes still misclassified \n",
      "\n",
      "Model# 13. 247 nodes still misclassified \n",
      "\n",
      "Model# 14. 247 nodes still misclassified \n",
      "\n",
      "Model# 15. 247 nodes still misclassified \n",
      "\n",
      "Model# 16. 247 nodes still misclassified \n",
      "\n",
      "Model# 17. 247 nodes still misclassified \n",
      "\n",
      "Model# 18. 247 nodes still misclassified \n",
      "\n",
      "Model# 19. 247 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48617/48617 [00:00<00:00, 1430125.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 645 nodes still misclassified \n",
      "\n",
      "Model# 1. 639 nodes still misclassified \n",
      "\n",
      "Model# 2. 636 nodes still misclassified \n",
      "\n",
      "Model# 3. 635 nodes still misclassified \n",
      "\n",
      "Model# 4. 635 nodes still misclassified \n",
      "\n",
      "Model# 5. 628 nodes still misclassified \n",
      "\n",
      "Model# 6. 627 nodes still misclassified \n",
      "\n",
      "Model# 7. 626 nodes still misclassified \n",
      "\n",
      "Model# 8. 620 nodes still misclassified \n",
      "\n",
      "Model# 9. 614 nodes still misclassified \n",
      "\n",
      "Model# 10. 559 nodes still misclassified \n",
      "\n",
      "Model# 11. 527 nodes still misclassified \n",
      "\n",
      "Model# 12. 527 nodes still misclassified \n",
      "\n",
      "Model# 13. 510 nodes still misclassified \n",
      "\n",
      "Model# 14. 507 nodes still misclassified \n",
      "\n",
      "Model# 15. 503 nodes still misclassified \n",
      "\n",
      "Model# 16. 434 nodes still misclassified \n",
      "\n",
      "Model# 17. 367 nodes still misclassified \n",
      "\n",
      "Model# 18. 367 nodes still misclassified \n",
      "\n",
      "Model# 19. 365 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48780/48780 [00:00<00:00, 1401798.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 912 nodes still misclassified \n",
      "\n",
      "Model# 1. 887 nodes still misclassified \n",
      "\n",
      "Model# 2. 876 nodes still misclassified \n",
      "\n",
      "Model# 3. 845 nodes still misclassified \n",
      "\n",
      "Model# 4. 837 nodes still misclassified \n",
      "\n",
      "Model# 5. 365 nodes still misclassified \n",
      "\n",
      "Model# 6. 352 nodes still misclassified \n",
      "\n",
      "Model# 7. 349 nodes still misclassified \n",
      "\n",
      "Model# 8. 347 nodes still misclassified \n",
      "\n",
      "Model# 9. 342 nodes still misclassified \n",
      "\n",
      "Model# 10. 342 nodes still misclassified \n",
      "\n",
      "Model# 11. 236 nodes still misclassified \n",
      "\n",
      "Model# 12. 235 nodes still misclassified \n",
      "\n",
      "Model# 13. 235 nodes still misclassified \n",
      "\n",
      "Model# 14. 204 nodes still misclassified \n",
      "\n",
      "Model# 15. 203 nodes still misclassified \n",
      "\n",
      "Model# 16. 203 nodes still misclassified \n",
      "\n",
      "Model# 17. 203 nodes still misclassified \n",
      "\n",
      "Model# 18. 203 nodes still misclassified \n",
      "\n",
      "Model# 19. 203 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48570/48570 [00:00<00:00, 1396031.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 934 nodes still misclassified \n",
      "\n",
      "Model# 1. 921 nodes still misclassified \n",
      "\n",
      "Model# 2. 898 nodes still misclassified \n",
      "\n",
      "Model# 3. 886 nodes still misclassified \n",
      "\n",
      "Model# 4. 868 nodes still misclassified \n",
      "\n",
      "Model# 5. 860 nodes still misclassified \n",
      "\n",
      "Model# 6. 596 nodes still misclassified \n",
      "\n",
      "Model# 7. 404 nodes still misclassified \n",
      "\n",
      "Model# 8. 402 nodes still misclassified \n",
      "\n",
      "Model# 9. 373 nodes still misclassified \n",
      "\n",
      "Model# 10. 368 nodes still misclassified \n",
      "\n",
      "Model# 11. 362 nodes still misclassified \n",
      "\n",
      "Model# 12. 355 nodes still misclassified \n",
      "\n",
      "Model# 13. 351 nodes still misclassified \n",
      "\n",
      "Model# 14. 350 nodes still misclassified \n",
      "\n",
      "Model# 15. 350 nodes still misclassified \n",
      "\n",
      "Model# 16. 346 nodes still misclassified \n",
      "\n",
      "Model# 17. 333 nodes still misclassified \n",
      "\n",
      "Model# 18. 333 nodes still misclassified \n",
      "\n",
      "Model# 19. 332 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48637/48637 [00:00<00:00, 1383790.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 703 nodes still misclassified \n",
      "\n",
      "Model# 1. 681 nodes still misclassified \n",
      "\n",
      "Model# 2. 681 nodes still misclassified \n",
      "\n",
      "Model# 3. 629 nodes still misclassified \n",
      "\n",
      "Model# 4. 627 nodes still misclassified \n",
      "\n",
      "Model# 5. 623 nodes still misclassified \n",
      "\n",
      "Model# 6. 577 nodes still misclassified \n",
      "\n",
      "Model# 7. 575 nodes still misclassified \n",
      "\n",
      "Model# 8. 538 nodes still misclassified \n",
      "\n",
      "Model# 9. 514 nodes still misclassified \n",
      "\n",
      "Model# 10. 463 nodes still misclassified \n",
      "\n",
      "Model# 11. 454 nodes still misclassified \n",
      "\n",
      "Model# 12. 429 nodes still misclassified \n",
      "\n",
      "Model# 13. 425 nodes still misclassified \n",
      "\n",
      "Model# 14. 375 nodes still misclassified \n",
      "\n",
      "Model# 15. 374 nodes still misclassified \n",
      "\n",
      "Model# 16. 371 nodes still misclassified \n",
      "\n",
      "Model# 17. 361 nodes still misclassified \n",
      "\n",
      "Model# 18. 359 nodes still misclassified \n",
      "\n",
      "Model# 19. 358 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48654/48654 [00:00<00:00, 1295993.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1414 nodes still misclassified \n",
      "\n",
      "Model# 1. 1402 nodes still misclassified \n",
      "\n",
      "Model# 2. 1358 nodes still misclassified \n",
      "\n",
      "Model# 3. 1339 nodes still misclassified \n",
      "\n",
      "Model# 4. 1059 nodes still misclassified \n",
      "\n",
      "Model# 5. 1041 nodes still misclassified \n",
      "\n",
      "Model# 6. 764 nodes still misclassified \n",
      "\n",
      "Model# 7. 753 nodes still misclassified \n",
      "\n",
      "Model# 8. 727 nodes still misclassified \n",
      "\n",
      "Model# 9. 726 nodes still misclassified \n",
      "\n",
      "Model# 10. 714 nodes still misclassified \n",
      "\n",
      "Model# 11. 693 nodes still misclassified \n",
      "\n",
      "Model# 12. 552 nodes still misclassified \n",
      "\n",
      "Model# 13. 546 nodes still misclassified \n",
      "\n",
      "Model# 14. 537 nodes still misclassified \n",
      "\n",
      "Model# 15. 537 nodes still misclassified \n",
      "\n",
      "Model# 16. 530 nodes still misclassified \n",
      "\n",
      "Model# 17. 528 nodes still misclassified \n",
      "\n",
      "Model# 18. 528 nodes still misclassified \n",
      "\n",
      "Model# 19. 459 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48765/48765 [00:00<00:00, 1389590.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 448 nodes still misclassified \n",
      "\n",
      "Model# 1. 425 nodes still misclassified \n",
      "\n",
      "Model# 2. 404 nodes still misclassified \n",
      "\n",
      "Model# 3. 394 nodes still misclassified \n",
      "\n",
      "Model# 4. 384 nodes still misclassified \n",
      "\n",
      "Model# 5. 331 nodes still misclassified \n",
      "\n",
      "Model# 6. 288 nodes still misclassified \n",
      "\n",
      "Model# 7. 280 nodes still misclassified \n",
      "\n",
      "Model# 8. 278 nodes still misclassified \n",
      "\n",
      "Model# 9. 230 nodes still misclassified \n",
      "\n",
      "Model# 10. 208 nodes still misclassified \n",
      "\n",
      "Model# 11. 207 nodes still misclassified \n",
      "\n",
      "Model# 12. 207 nodes still misclassified \n",
      "\n",
      "Model# 13. 207 nodes still misclassified \n",
      "\n",
      "Model# 14. 206 nodes still misclassified \n",
      "\n",
      "Model# 15. 205 nodes still misclassified \n",
      "\n",
      "Model# 16. 204 nodes still misclassified \n",
      "\n",
      "Model# 17. 203 nodes still misclassified \n",
      "\n",
      "Model# 18. 203 nodes still misclassified \n",
      "\n",
      "Model# 19. 203 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48678/48678 [00:00<00:00, 1415775.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 818 nodes still misclassified \n",
      "\n",
      "Model# 1. 528 nodes still misclassified \n",
      "\n",
      "Model# 2. 514 nodes still misclassified \n",
      "\n",
      "Model# 3. 490 nodes still misclassified \n",
      "\n",
      "Model# 4. 468 nodes still misclassified \n",
      "\n",
      "Model# 5. 434 nodes still misclassified \n",
      "\n",
      "Model# 6. 403 nodes still misclassified \n",
      "\n",
      "Model# 7. 375 nodes still misclassified \n",
      "\n",
      "Model# 8. 344 nodes still misclassified \n",
      "\n",
      "Model# 9. 340 nodes still misclassified \n",
      "\n",
      "Model# 10. 299 nodes still misclassified \n",
      "\n",
      "Model# 11. 267 nodes still misclassified \n",
      "\n",
      "Model# 12. 267 nodes still misclassified \n",
      "\n",
      "Model# 13. 267 nodes still misclassified \n",
      "\n",
      "Model# 14. 267 nodes still misclassified \n",
      "\n",
      "Model# 15. 267 nodes still misclassified \n",
      "\n",
      "Model# 16. 265 nodes still misclassified \n",
      "\n",
      "Model# 17. 247 nodes still misclassified \n",
      "\n",
      "Model# 18. 245 nodes still misclassified \n",
      "\n",
      "Model# 19. 245 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48515/48515 [00:00<00:00, 1354690.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1038 nodes still misclassified \n",
      "\n",
      "Model# 1. 1018 nodes still misclassified \n",
      "\n",
      "Model# 2. 1004 nodes still misclassified \n",
      "\n",
      "Model# 3. 1001 nodes still misclassified \n",
      "\n",
      "Model# 4. 1001 nodes still misclassified \n",
      "\n",
      "Model# 5. 997 nodes still misclassified \n",
      "\n",
      "Model# 6. 635 nodes still misclassified \n",
      "\n",
      "Model# 7. 630 nodes still misclassified \n",
      "\n",
      "Model# 8. 626 nodes still misclassified \n",
      "\n",
      "Model# 9. 625 nodes still misclassified \n",
      "\n",
      "Model# 10. 622 nodes still misclassified \n",
      "\n",
      "Model# 11. 482 nodes still misclassified \n",
      "\n",
      "Model# 12. 425 nodes still misclassified \n",
      "\n",
      "Model# 13. 411 nodes still misclassified \n",
      "\n",
      "Model# 14. 395 nodes still misclassified \n",
      "\n",
      "Model# 15. 393 nodes still misclassified \n",
      "\n",
      "Model# 16. 351 nodes still misclassified \n",
      "\n",
      "Model# 17. 343 nodes still misclassified \n",
      "\n",
      "Model# 18. 309 nodes still misclassified \n",
      "\n",
      "Model# 19. 309 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48717/48717 [00:00<00:00, 1480305.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 779 nodes still misclassified \n",
      "\n",
      "Model# 1. 760 nodes still misclassified \n",
      "\n",
      "Model# 2. 737 nodes still misclassified \n",
      "\n",
      "Model# 3. 671 nodes still misclassified \n",
      "\n",
      "Model# 4. 661 nodes still misclassified \n",
      "\n",
      "Model# 5. 648 nodes still misclassified \n",
      "\n",
      "Model# 6. 516 nodes still misclassified \n",
      "\n",
      "Model# 7. 386 nodes still misclassified \n",
      "\n",
      "Model# 8. 374 nodes still misclassified \n",
      "\n",
      "Model# 9. 361 nodes still misclassified \n",
      "\n",
      "Model# 10. 348 nodes still misclassified \n",
      "\n",
      "Model# 11. 340 nodes still misclassified \n",
      "\n",
      "Model# 12. 338 nodes still misclassified \n",
      "\n",
      "Model# 13. 336 nodes still misclassified \n",
      "\n",
      "Model# 14. 334 nodes still misclassified \n",
      "\n",
      "Model# 15. 310 nodes still misclassified \n",
      "\n",
      "Model# 16. 294 nodes still misclassified \n",
      "\n",
      "Model# 17. 292 nodes still misclassified \n",
      "\n",
      "Model# 18. 292 nodes still misclassified \n",
      "\n",
      "Model# 19. 292 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48673/48673 [00:00<00:00, 1424350.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 554 nodes still misclassified \n",
      "\n",
      "Model# 1. 539 nodes still misclassified \n",
      "\n",
      "Model# 2. 472 nodes still misclassified \n",
      "\n",
      "Model# 3. 466 nodes still misclassified \n",
      "\n",
      "Model# 4. 422 nodes still misclassified \n",
      "\n",
      "Model# 5. 372 nodes still misclassified \n",
      "\n",
      "Model# 6. 371 nodes still misclassified \n",
      "\n",
      "Model# 7. 367 nodes still misclassified \n",
      "\n",
      "Model# 8. 366 nodes still misclassified \n",
      "\n",
      "Model# 9. 362 nodes still misclassified \n",
      "\n",
      "Model# 10. 359 nodes still misclassified \n",
      "\n",
      "Model# 11. 358 nodes still misclassified \n",
      "\n",
      "Model# 12. 357 nodes still misclassified \n",
      "\n",
      "Model# 13. 356 nodes still misclassified \n",
      "\n",
      "Model# 14. 356 nodes still misclassified \n",
      "\n",
      "Model# 15. 355 nodes still misclassified \n",
      "\n",
      "Model# 16. 355 nodes still misclassified \n",
      "\n",
      "Model# 17. 355 nodes still misclassified \n",
      "\n",
      "Model# 18. 355 nodes still misclassified \n",
      "\n",
      "Model# 19. 278 nodes still misclassified \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric import utils\n",
    "\n",
    "################################## Training Main Model #####################################\n",
    "if Train_Gnn:\n",
    "    for i in range(95):\n",
    "        f = open(f\"unicorn/{i}.txt\")\n",
    "        data = f.read().split('\\n')\n",
    "\n",
    "        data = [line.split('\\t') for line in data]\n",
    "        df = pd.DataFrame (data, columns = ['actorID', 'actor_type','objectID','object','action','timestamp'])\n",
    "        df.sort_values(by='timestamp', ascending=True,inplace=True)\n",
    "        df = df.dropna()\n",
    "        phrases,labels,edges,mapp = prepare_graph(df)\n",
    "\n",
    "        criterion = CrossEntropyLoss()\n",
    "\n",
    "        nodes = [infer(x) for x in phrases]\n",
    "        nodes = np.array(nodes)  \n",
    "\n",
    "        graph = Data(x=torch.tensor(nodes,dtype=torch.float).to(device),y=torch.tensor(labels,dtype=torch.long).to(device), edge_index=torch.tensor(edges,dtype=torch.long).to(device))\n",
    "        graph.n_id = torch.arange(graph.num_nodes)\n",
    "        mask = torch.tensor([True]*graph.num_nodes, dtype=torch.bool)\n",
    "\n",
    "        for m_n in range(20):\n",
    "            loader = NeighborLoader(graph, num_neighbors=[-1,-1], batch_size=5000,input_nodes=mask)\n",
    "            total_loss = 0\n",
    "            for subg in loader:\n",
    "                model.train()\n",
    "                optimizer.zero_grad() \n",
    "                out = model(subg.x, subg.edge_index) \n",
    "                loss = criterion(out, subg.y) \n",
    "                loss.backward() \n",
    "                optimizer.step()      \n",
    "                total_loss += loss.item() * subg.batch_size\n",
    "\n",
    "            loader = NeighborLoader(graph, num_neighbors=[-1,-1], batch_size=5000,input_nodes=mask)\n",
    "            for subg in loader:\n",
    "              model.eval()\n",
    "              out = model(subg.x, subg.edge_index)\n",
    "              sorted, indices = out.sort(dim=1,descending=True)\n",
    "              conf = (sorted[:,0] - sorted[:,1]) / sorted[:,0]\n",
    "              conf = (conf - conf.min()) / conf.max()\n",
    "              pred = indices[:,0]\n",
    "              cond = (pred == subg.y)\n",
    "              mask[subg.n_id[cond]] = False\n",
    "\n",
    "            print(f'Model# {m_n}. {mask.sum().item()} nodes still misclassified \\n')\n",
    "            torch.save(model.state_dict(), f'trained_weights/unicorn/unicorn{m_n}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph #: 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48518/48518 [00:00<00:00, 1353341.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397 1.8583532275429482\n",
      "Graph #: 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48642/48642 [00:00<00:00, 1442648.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346 2.1005342399222924\n",
      "Graph #: 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48671/48671 [00:00<00:00, 1116549.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347 2.0265140454359636\n"
     ]
    }
   ],
   "source": [
    "for i in range(95,98):\n",
    "    print(f\"Graph #: {i}\")\n",
    "    f = open(f\"unicorn/{i}.txt\")\n",
    "    data = f.read().split('\\n')\n",
    "\n",
    "    data = [line.split('\\t') for line in data]\n",
    "    df = pd.DataFrame (data, columns = ['actorID', 'actor_type','objectID','object','action','timestamp'])\n",
    "    df.sort_values(by='timestamp', ascending=True,inplace=True)\n",
    "    df = df.dropna()\n",
    "\n",
    "    phrases,labels,edges,mapp = prepare_graph(df)\n",
    "\n",
    "    nodes = [infer(x) for x in phrases]\n",
    "    nodes = np.array(nodes)  \n",
    "\n",
    "    graph = Data(x=torch.tensor(nodes,dtype=torch.float).to(device),y=torch.tensor(labels,dtype=torch.long).to(device), edge_index=torch.tensor(edges,dtype=torch.long).to(device))\n",
    "    graph.n_id = torch.arange(graph.num_nodes)\n",
    "    flag = torch.tensor([True]*graph.num_nodes, dtype=torch.bool)\n",
    "\n",
    "    for m_n in range(20):\n",
    "        model.load_state_dict(torch.load(f'trained_weights/unicorn/unicorn{m_n}.pth'))\n",
    "        model.eval()\n",
    "        out = model(graph.x, graph.edge_index)\n",
    "\n",
    "        sorted, indices = out.sort(dim=1,descending=True)\n",
    "        conf = (sorted[:,0] - sorted[:,1]) / sorted[:,0]\n",
    "        conf = (conf - conf.min()) / conf.max()\n",
    "\n",
    "        pred = indices[:,0]\n",
    "        cond = (pred == graph.y)\n",
    "        flag[graph.n_id[cond]] = torch.logical_and(flag[graph.n_id[cond]], torch.tensor([False]*len(flag[graph.n_id[cond]]), dtype=torch.bool))\n",
    "            \n",
    "    print(flag.sum().item(), (flag.sum().item() / len(flag))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "thresh = 330"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph #: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48728/48728 [00:00<00:00, 1373254.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211 1.3069871159563924\n",
      "Graph #: 101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48577/48577 [00:00<00:00, 1340968.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406 2.0751341681574242\n",
      "Graph #: 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48613/48613 [00:00<00:00, 1341194.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334 1.8205603401286383\n",
      "Graph #: 103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48592/48592 [00:00<00:00, 1394075.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393 2.1411059656769273\n",
      "Graph #: 104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48569/48569 [00:00<00:00, 1332390.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407 2.166853005377203\n",
      "Graph #: 105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48645/48645 [00:00<00:00, 1366123.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308 1.7289772089367914\n",
      "Graph #: 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48608/48608 [00:00<00:00, 1358933.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320 1.5923566878980893\n",
      "Graph #: 107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38821/38821 [00:00<00:00, 1456075.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337 1.9044927945747387\n",
      "Graph #: 108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39121/39121 [00:00<00:00, 1419669.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167 1.9647058823529413\n",
      "Graph #: 109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38944/38944 [00:00<00:00, 1437068.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426 3.1741300946278224\n",
      "Graph #: 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38854/38854 [00:00<00:00, 1300145.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268 1.6758379189594799\n",
      "Graph #: 111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38838/38838 [00:00<00:00, 1406478.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379 2.4988461792048526\n",
      "Graph #: 112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38791/38791 [00:00<00:00, 1306805.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370 2.1735299300945776\n",
      "Graph #: 113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38939/38939 [00:00<00:00, 1401376.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293 2.168282394731\n",
      "Graph #: 114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38905/38905 [00:00<00:00, 711992.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251 1.728293052399642\n",
      "Graph #: 115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38930/38930 [00:00<00:00, 1382663.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310 2.2176121324844407\n",
      "Graph #: 116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38818/38818 [00:00<00:00, 1461832.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362 2.0627956008889394\n",
      "Graph #: 117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38881/38881 [00:00<00:00, 1346078.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 1.5764517519551695\n",
      "Graph #: 118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38955/38955 [00:00<00:00, 1395283.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266 1.87694044594976\n",
      "Graph #: 119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39034/39034 [00:00<00:00, 1516449.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164 1.2959304622678782\n",
      "Graph #: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38883/38883 [00:00<00:00, 1356369.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325 2.1081992734820965\n",
      "Graph #: 121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39047/39047 [00:00<00:00, 1176527.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176 1.6632016632016633\n",
      "Graph #: 122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38877/38877 [00:00<00:00, 1332042.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290 1.7777232881750749\n",
      "Graph #: 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38934/38934 [00:00<00:00, 1434856.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347 2.656561016689634\n",
      "Graph #: 124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38814/38814 [00:00<00:00, 1450675.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378 2.2198731501057085\n"
     ]
    }
   ],
   "source": [
    "correct_benign = 0\n",
    "\n",
    "for i in range(100,125):\n",
    "    print(f\"Graph #: {i}\")\n",
    "    f = open(f\"unicorn/{i}.txt\")\n",
    "    data = f.read().split('\\n')\n",
    "\n",
    "    data = [line.split('\\t') for line in data]\n",
    "    df = pd.DataFrame (data, columns = ['actorID', 'actor_type','objectID','object','action','timestamp'])\n",
    "    df.sort_values(by='timestamp', ascending=True,inplace=True)\n",
    "    df = df.dropna()\n",
    "\n",
    "    phrases,labels,edges,mapp = prepare_graph(df)\n",
    "\n",
    "    nodes = [infer(x) for x in phrases]\n",
    "    nodes = np.array(nodes)  \n",
    "\n",
    "    graph = Data(x=torch.tensor(nodes,dtype=torch.float).to(device),y=torch.tensor(labels,dtype=torch.long).to(device), edge_index=torch.tensor(edges,dtype=torch.long).to(device))\n",
    "    graph.n_id = torch.arange(graph.num_nodes)\n",
    "    flag = torch.tensor([True]*graph.num_nodes, dtype=torch.bool)\n",
    "\n",
    "    for m_n in range(20):\n",
    "        model.load_state_dict(torch.load(f'trained_weights/unicorn/unicorn{m_n}.pth'))\n",
    "        model.eval()\n",
    "        out = model(graph.x, graph.edge_index)\n",
    "\n",
    "        sorted, indices = out.sort(dim=1,descending=True)\n",
    "        conf = (sorted[:,0] - sorted[:,1]) / sorted[:,0]\n",
    "        conf = (conf - conf.min()) / conf.max()\n",
    "\n",
    "        pred = indices[:,0]\n",
    "        cond = (pred == graph.y)\n",
    "        flag[graph.n_id[cond]] = torch.logical_and(flag[graph.n_id[cond]], torch.tensor([False]*len(flag[graph.n_id[cond]]), dtype=torch.bool))\n",
    "\n",
    "    if flag.sum().item() <= thresh:\n",
    "        correct_benign = correct_benign + 1\n",
    "            \n",
    "    print(flag.sum().item(), (flag.sum().item() / len(flag))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph #: 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38910/38910 [00:00<00:00, 1349867.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306 2.8042521994134897\n",
      "Graph #: 126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38921/38921 [00:00<00:00, 772552.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280 2.083333333333333\n",
      "Graph #: 127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38882/38882 [00:00<00:00, 1421127.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320 2.216219959831013\n",
      "Graph #: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38983/38983 [00:00<00:00, 723345.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244 2.212349261039079\n",
      "Graph #: 129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38816/38816 [00:00<00:00, 1392433.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325 2.401891951814352\n",
      "Graph #: 130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38808/38808 [00:00<00:00, 1370727.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407 2.7104421949920083\n",
      "Graph #: 131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38773/38773 [00:00<00:00, 1393512.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451 3.125866370945384\n",
      "Graph #: 132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38896/38896 [00:00<00:00, 1386539.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413 3.292673204177629\n",
      "Graph #: 133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38773/38773 [00:00<00:00, 1403591.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357 2.207928752551178\n",
      "Graph #: 134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38860/38860 [00:00<00:00, 1370855.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376 2.64156245609105\n",
      "Graph #: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38989/38989 [00:00<00:00, 1431387.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322 3.225806451612903\n",
      "Graph #: 136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38897/38897 [00:00<00:00, 1274915.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341 2.703988581397193\n",
      "Graph #: 137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38921/38921 [00:00<00:00, 1458170.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280 2.4639211545230553\n",
      "Graph #: 138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38819/38819 [00:00<00:00, 1367787.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361 2.2458628841607564\n",
      "Graph #: 139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39034/39034 [00:00<00:00, 1431736.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295 2.927749106788408\n",
      "Graph #: 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38822/38822 [00:00<00:00, 1383843.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440 3.064066852367688\n",
      "Graph #: 141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38767/38767 [00:00<00:00, 1360879.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333 2.1893491124260356\n",
      "Graph #: 142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38936/38936 [00:00<00:00, 1477766.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264 2.0500077651809288\n",
      "Graph #: 143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38940/38940 [00:00<00:00, 1071005.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325 2.8735632183908044\n",
      "Graph #: 144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38770/38770 [00:00<00:00, 1336180.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395 2.4755577839057405\n",
      "Graph #: 145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38868/38868 [00:00<00:00, 1400900.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318 2.4038098117771565\n",
      "Graph #: 146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38773/38773 [00:00<00:00, 1362184.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404 2.8077003266384044\n",
      "Graph #: 147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38778/38778 [00:00<00:00, 1402985.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420 2.8345818991698724\n",
      "Graph #: 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38799/38799 [00:00<00:00, 1383599.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354 2.311610291236777\n",
      "Graph #: 149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38807/38807 [00:00<00:00, 1378831.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264 1.65860400829302\n"
     ]
    }
   ],
   "source": [
    "correct_attack = 0\n",
    "\n",
    "for i in range(125,150):\n",
    "    print(f\"Graph #: {i}\")\n",
    "    f = open(f\"unicorn/{i}.txt\")\n",
    "    data = f.read().split('\\n')\n",
    "\n",
    "    data = [line.split('\\t') for line in data]\n",
    "    df = pd.DataFrame (data, columns = ['actorID', 'actor_type','objectID','object','action','timestamp'])\n",
    "    df.sort_values(by='timestamp', ascending=True,inplace=True)\n",
    "    df = df.dropna()\n",
    "    \n",
    "    phrases,labels,edges,mapp = prepare_graph(df)\n",
    "\n",
    "    nodes = [infer(x) for x in phrases]\n",
    "    nodes = np.array(nodes)  \n",
    "    \n",
    "    graph = Data(x=torch.tensor(nodes,dtype=torch.float).to(device),y=torch.tensor(labels,dtype=torch.long).to(device), edge_index=torch.tensor(edges,dtype=torch.long).to(device))\n",
    "    graph.n_id = torch.arange(graph.num_nodes)\n",
    "    flag = torch.tensor([True]*graph.num_nodes, dtype=torch.bool)\n",
    "\n",
    "    for m_n in range(20):\n",
    "        model.load_state_dict(torch.load(f'trained_weights/unicorn/unicorn{m_n}.pth'))\n",
    "        model.eval()\n",
    "        out = model(graph.x, graph.edge_index)\n",
    "\n",
    "        sorted, indices = out.sort(dim=1,descending=True)\n",
    "        conf = (sorted[:,0] - sorted[:,1]) / sorted[:,0]\n",
    "        conf = (conf - conf.min()) / conf.max()\n",
    "\n",
    "        pred = indices[:,0]\n",
    "        cond = (pred == graph.y)\n",
    "        flag[graph.n_id[cond]] = torch.logical_and(flag[graph.n_id[cond]], torch.tensor([False]*len(flag[graph.n_id[cond]]), dtype=torch.bool))\n",
    "\n",
    "    if  flag.sum().item() > thresh:\n",
    "        correct_attack = correct_attack + 1\n",
    "   \n",
    "    print(flag.sum().item(), (flag.sum().item() / len(flag))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of True Positives (TP): 13\n",
      "Number of False Positives (FP): 11\n",
      "Number of False Negatives (FN): 12\n",
      "Number of True Negatives (TN): 14\n",
      "\n",
      "Precision: 0.5416666666666666\n",
      "Recall: 0.52\n",
      "Fscore: 0.5306122448979592\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TP = correct_attack\n",
    "FP = 25 - correct_benign\n",
    "TN = correct_benign\n",
    "FN = 25 - correct_attack\n",
    "\n",
    "FPR = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
    "TPR = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "print(f\"Number of True Positives (TP): {TP}\")\n",
    "print(f\"Number of False Positives (FP): {FP}\")\n",
    "print(f\"Number of False Negatives (FN): {FN}\")\n",
    "print(f\"Number of True Negatives (TN): {TN}\\n\")\n",
    "\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "recall = TPR  \n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "fscore = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "print(f\"Fscore: {fscore}\\n\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "flash_amaan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
